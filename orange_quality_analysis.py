# -*- coding: utf-8 -*-
"""Cópia de Orange - Quality Analysis Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PCQlGfqZ03aYz13gjknJY2AknzfBIRtX

---

# Análise Exploratória de Dados
 - Conjunto de dados: `orange_quality` (Laranja Mecânica)
 - Alunos:
   - Vanessa Fermino dos Santos Cavalcante
   - Ana Marly do Couto da Silva
   - Romeu Róseo
   - José Abílio
---

## Preparação
 - Carregamento de bibliotecas
 - Configuração de estilo dos gráficos
 - Leitura do conjunto de dados
"""

# @title Carregando bibliotecas

import itertools
import pandas as pd
import numpy as np
from scipy import stats as st
from matplotlib import pyplot as plt
import seaborn as sns
from IPython.display import Markdown

# sns.set_style("whitegrid")
sns.set_theme(style="whitegrid", palette="colorblind")

palette_dict = {
    'day': 'Set1',   # Exemplo de paleta para 'day'
    'time': 'Dark2', # Exemplo de paleta para 'time'
    'smoker': 'coolwarm', # Paleta para 'smoker'
    'sex': 'Pastel1',   # Paleta para 'sex'
}

# @title Leitura do conjunto de dados
df = pd.read_csv(
    "https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv"
)
df.head()

"""# Informações iniciais"""

display(Markdown("### Primeiras linhas"))
display(df.head())

display(Markdown("### Ultimas linhas"))
display(df.tail())

display(Markdown("### Informação das variáveis"))
df.info()

display(Markdown("### Quantidade de valores únicos"))
df.nunique()

"""# Dados faltantes"""

df.isnull().sum()

"""A partir das informações iniciais, podemos dizer que:

*   O conjunto de dados tem 241 unidades amostrais com 11 variáveis(columns)
*   Não há valores ausentes em nenhuma das colunas.
*   Todas as colunas são do tipo numérico (inteiro ou float), exceto pelas colunas "Color", "Variety" e "Blemishes (Y/N)" que são do tipo objeto (texto).


*   Classificação das variáveis:


    *  Quantitativa contínua: Size (cm), Weight (g),Brix (Sweetness), pH (Acidity)
    *   Quantitativa discreta: HarvestTime (days)
    *   Qualitativa nominal: Color, Variety, Blemishes (Y/N), Quality (1–5)
    *   Qualitativa ordinal: Softness (1–5), Ripeness (1–5)


"""

# @title Dicionário de dados
df_dict = pd.DataFrame([
    {
        "variavel": "Size (cm)",
        "descricao": "Medida em centímetros.",
        "tipo": "Quantitativa",
        "subtipo": "contínua",
    },
    {
        "variavel": "Weight (g)",
        "descricao": "Medida em gramas.",
        "tipo": "Quantitativa",
        "subtipo": "contínua",
    },
    {
        "variavel": "Brix (Sweetness)",
        "descricao": "Grau de doçura, normalmente em escala contínua (°Brix).",
        "tipo": "Quantitativa",
        "subtipo": "contínua",
    },
    {
        "variavel": "pH (Acidity)",
        "descricao": "Escala contínua de acidez.",
        "tipo": "Quantitativa",
        "subtipo": "contínua",
    },
    {
        "variavel": "Softness (1-5)",
        "descricao": "Escala de 1 a 5, reflete percepção de maciez/textura da fruta.",
        "tipo": "Qualitativa",
        "subtipo": "ordinal",
    },
    {
        "variavel": "HarvestTime (days)",
        "descricao": "Dias até a colheita (contagem inteira).",
        "tipo": "Quantitativa",
        "subtipo": "discreta",
    },
    {
        "variavel": "Ripeness (1-5)",
        "descricao": "Grau de maturação em escala de 1 a 5.",
        "tipo": "Qualitativa",
        "subtipo": "ordinal",
    },
    {
        "variavel": "Color",
        "descricao": "Cor da fruta.",
        "tipo": "Qualitativa",
        "subtipo": "nominal",
    },
    {
        "variavel": "Variety",
        "descricao": "Nome da variedade da fruta",
        "tipo": "Qualitativa",
        "subtipo": "nominal",
    },
    {
        "variavel": "Blemishes (Y/N)",
        "descricao": "Presença ou não de defeitos",
        "tipo": "Qualitativa",
        "subtipo": "nominal",
    },
    {
        "variavel": "Quality (1-5)",
        "descricao": "Avaliação de qualidade em escala de 1 a 5",
        "tipo": "Qualitativa",
        "subtipo": "ordinal",
    }
])
df_dict

"""# Análise univariada

# Resumo estatístico
"""

print("--- Verificando os tipos de dados das colunas ---")
df.info()

# @title Resumo estatístico

display(Markdown("### Variáveis qualitativas"))
print(df.describe(include='object'))

display(Markdown("### Variáveis quantitativas"))
print(df.describe())

"""# Resumo da Análise Inicial:

Tamanho e Peso: O tamanho médio das laranjas é de 7.84 cm e o peso médio é de 205.12 gramas.

Doçura e Acidez: A doçura (Brix) e a acidez (pH) parecem estar dentro de uma faixa consistente, com médias de 10.90 e 3.47, respectivamente.

Qualidade: A qualidade das laranjas, em uma escala de 1 a 5, tem uma média de 3.81, indicando que, no geral, as laranjas deste conjunto de dados são de boa qualidade.

Variedades e Cores: As variedades mais comuns são "Cara Cara" e "Star Ruby". A cor predominante é "Deep Orange".

Manchas: A maioria das laranjas não apresenta manchas ("Blemishes (Y/N)" = N).

# Distribuição de Variáveis

# Variáveis Qualitativas
"""

# Identificar variáveis qualitativas
variaveis_qualitativas = df.select_dtypes(include=['object']).columns.tolist()


# Remover a variável 'Color' da lista de variáveis qualitativas
if 'Color' in variaveis_qualitativas:
    variaveis_qualitativas.remove('Color')

print("\n--- Análise Univariada: Variáveis Qualitativas (exceto 'Color') ---")

# Tabelas de Frequência
for var in variaveis_qualitativas:
    print(f"\nTabela de Frequência para a variável '{var}':")
    print(df[var].value_counts())
    print("-" * 30)

# Visualizações (Gráficos de Barras)
num_qual_vars = len(variaveis_qualitativas)

# Apenas criar gráficos se houver variáveis qualitativas restantes
if num_qual_vars > 0:
    fig, axes = plt.subplots(figsize=(10, 5 * num_qual_vars), ncols=1, nrows=num_qual_vars) # Ajustado para plots verticais
    if num_qual_vars == 1:
        axes = [axes]
    fig.suptitle('Distribuição das Variáveis Qualitativas', fontsize=16)

    for i, variavel in enumerate(variaveis_qualitativas):
        order = df[variavel].value_counts().index
        ax = sns.countplot(data=df, y=variavel, ax=axes[i], order=order, palette='viridis', alpha=0.8)
        ax.bar_label(ax.containers[0], fmt="%d", color="black", label_type="edge", fontweight='bold', padding=5)
        ax.set(title=f"Distribuição de '{variavel}'", xlabel="Contagem", ylabel="")
        for side in ["bottom","top", "right"]:
            ax.spines[side].set_visible(False)
        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: int(x)))

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.savefig('qualitative_analysis.png')
    print("\nGráficos das variáveis qualitativas salvos em 'qualitative_analysis.png'")
else:
    print("\nNenhuma variável qualitativa para analisar após a remoção de 'cor'.")

"""# Variáveis Quantitativas"""

# Identificar variáveis quantitativas
variaveis_quantitativas = df.select_dtypes(include=['number']).columns.tolist()

print("--- Análise Univariada: Variáveis Quantitativas ---")
print("\nEstatísticas Descritivas:")
print(df[variaveis_quantitativas].describe())

# Visualizações (Histogramas e Boxplots)
num_quant_vars = len(variaveis_quantitativas)
fig, axes = plt.subplots(nrows=num_quant_vars, ncols=2, figsize=(12, num_quant_vars * 4))
fig.suptitle('Distribuição das Variáveis Quantitativas', fontsize=16, y=1.02)

for i, var in enumerate(variaveis_quantitativas):
    # Histograma
    sns.histplot(df[var], kde=True, ax=axes[i, 0])
    axes[i, 0].set_title(f'Histograma de {var}')
    axes[i, 0].set_xlabel('')
    axes[i, 0].set_ylabel('Frequência')

    # Boxplot
    sns.boxplot(x=df[var], ax=axes[i, 1])
    axes[i, 1].set_title(f'Boxplot de {var}')
    axes[i, 1].set_xlabel('')

plt.tight_layout(rect=[0, 0, 1, 0.99])
plt.savefig('quantitative_analysis.png')
print("\nGráficos das variáveis quantitativas salvos em 'quantitative_analysis.png'")

"""A análise univariada nos mostra que o dataset representa um lote de laranjas de boa qualidade geral (nota média 3.81, 75% sem manchas), com sabor consistente (baixa variação de doçura), mas com tamanhos e pesos variados."""

# Lista das variáveis numéricas que queremos comparar entre as variedades
variaveis_para_analise = ['Size (cm)', 'Weight (g)', 'Brix (Sweetness)', 'pH (Acidity)']

# Criar uma figura para colocar nossos gráficos
# Teremos 2 linhas e 2 colunas de gráficos
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))
# Transforma a matriz de eixos 2x2 em uma lista para facilitar o loop
axes = axes.flatten()

fig.suptitle('Comparação das Características Numéricas por Variedade', fontsize=18, y=1.03)

# Loop para criar um boxplot para cada variável numérica
for i, var_numerica in enumerate(variaveis_para_analise):
    sns.boxplot(data=df, x=var_numerica, y='Variety', ax=axes[i], palette='pastel')

    axes[i].set_title(f'Distribuição de "{var_numerica}" por Variedade', fontsize=14)
    axes[i].set_xlabel(var_numerica, fontsize=12)
    axes[i].set_ylabel('Variedade', fontsize=12)

# Ajusta o layout para evitar que os títulos se sobreponham
plt.tight_layout()
# Salva a figura em um arquivo
plt.savefig('boxplot_horizontal_por_variedade.png')

print("\nGráfico comparativo de boxplots horizontais salvo em 'boxplot_horizontal_por_variedade.png'")

"""# Análise Bivariada

##Variáveis Quantitativas
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap

# Leitura do Conjunto de Dados
df = pd.read_csv(
    "https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv"
)

# Lista de variáveis quantitativas
variaveis_quantitativas = ['Size (cm)', 'Weight (g)', 'Brix (Sweetness)', 'pH (Acidity)', 'HarvestTime (days)']

# Matriz de correlação
correlation_matrix = df[variaveis_quantitativas].corr()

# Exibir a matriz
print("🔗 Correlação Geral entre Variáveis Quantitativas:")
print(correlation_matrix)

# Criar paleta divergente: creme → amarelo → laranja → marrom
colors = ["#f5f5dc", "#ffffcc", "#ffcc66", "#cc6600"]
# creme, amarelo claro, laranja, marrom

# Visualizar com mapa de calor
creme_orange_cmap = LinearSegmentedColormap.from_list("CremeOrange", colors, N=256)
sns.heatmap(
    correlation_matrix,
    annot=True,
    cmap=creme_orange_cmap,
    fmt=".2f",
    center=0,
    vmin=-0.2,
    vmax=1.0
)

plt.title('Matriz de Correlação Quantitativa Geral')
plt.show()
plt.savefig('Matriz_corr_quant')

"""#Análise Geral das Correlações entre Variáveis Quantitativas

A matriz de correlação geral mostra importantes dados entre as variáveis físicas e químicas das frutas contidas no dataset. Embora os números de correlação não sejam extremamente altos, alguns padrões interessantes podem ser encontrados:

• 	**Tamanho (Size) e Peso (Weight)**:

Apresentam uma correlação positiva moderada
(r = 0.31), indicando que frutas maiores tendem a ser mais pesadas, como esperado. Essa relação é coerente com a lógica física do crescimento dos frutos.

• 	**Brix (Sweetness)** que representa o grau de doçura:

Mostra correlação negativa com as variáveis;

1. Size (r = –0.31) e Weight (r = –0.24), sugerindo que frutas maiores e mais
pesadas tendem a ser menos doces.

2. pH (Acidity) (r = –0.30) indicando que frutas mais doces tendem a ser mais ácidas — uma relação interessante que pode refletir o estágio de maturação ou características de cada variedade.


• 	**pH (Acidity)**:

Tem correlação positiva com Size (r = 0.33) e Weight (r = 0.30), o que pode indicar que frutas maiores apresentam menor acidez relativa.

• 	**HarvestTime (days)** ou tempo até a colheita:

Apresenta correlações positivas discretas com Size (r = 0.30) e Weight (r = 0.33), sugerindo que frutas colhidas mais tardiamente tendem a ser maiores e mais pesadas.

Por outro lado, sua correlação com Brix é negativa (r = –0.26), o que pode indicar que o prolongamento do tempo de colheita não necessariamente aumenta a doçura.

"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools
import math
import numpy as np
from matplotlib.patches import Patch

# Leitura de Conjunto de Dados
df = pd.read_csv("https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv")

# Variáveis quantitativas
variaveis_quantitativas = ['Size (cm)', 'Weight (g)', 'Brix (Sweetness)', 'pH (Acidity)', 'HarvestTime (days)']

# Número de colunas
num_cols = 3
pairs = list(itertools.combinations(variaveis_quantitativas, 2))
num_rows = math.ceil(len(pairs) / num_cols)

# Dicionário de cores por variável
color_map = {
    'Size (cm)': '#1f77b4',        # azul
    'Weight (g)': '#ff7f0e',       # laranja
    'Brix (Sweetness)': '#2ca02c', # verde
    'pH (Acidity)': '#d62728',     # vermelho
    'HarvestTime (days)': '#9467bd' # roxo
}

# Criar figura com subplots
fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(7 * num_cols, 5.5 * num_rows))
axes = axes.flatten()

for i, (var1, var2) in enumerate(pairs):
    # Normalizar valores para interpolação de cor
    norm1 = (df[var1] - df[var1].min()) / (df[var1].max() - df[var1].min())
    norm2 = (df[var2] - df[var2].min()) / (df[var2].max() - df[var2].min())
    blend = (norm1 + norm2) / 2

    # Criar colormap entre as duas cores
    cmap = sns.blend_palette([color_map[var1], color_map[var2]], as_cmap=True)
    colors = cmap(blend)

    axes[i].scatter(
        df[var1],
        df[var2],
        c=colors,
        alpha=0.7,
        s=40
    )

    axes[i].set_title(f'{var1} vs {var2}', fontsize=13)
    axes[i].set_xlabel(var1, fontsize=11)
    axes[i].set_ylabel(var2, fontsize=11)
    axes[i].grid(True)

    coef = df[[var1, var2]].corr().iloc[0, 1]
    print(f"📈 Correlação entre '{var1}' e '{var2}': {coef:.2f}")
    print("-" * 50)

# Remover eixos extras se houver
for j in range(i + 1, len(axes)):
    axes[j].axis('off')

# Espaçamento entre os gráficos
plt.subplots_adjust(wspace=0.4, hspace=0.5)

# Título geral
fig.suptitle('Matriz de Correlação entre os Pares de Variáveis Quantitativas', fontsize=20, y=0.94)

# Legendas título e gráficos
legend_elements = [Patch(facecolor=color_map[var], label=var) for var in variaveis_quantitativas]

fig.legend(
    handles=legend_elements,
    loc='upper center',
    bbox_to_anchor=(0.5, 0.89),
    ncol=len(variaveis_quantitativas),
    frameon=False,
    fontsize=10,
    title='Cores atribuídas às variáveis'
)

plt.tight_layout(rect=[0, 0, 1, 0.86])
plt.show()

"""# Análise Visual por Gráficos de Dispersão

Para complementar a leitura estatística, foram gerados gráficos de dispersão entre todos os pares de variáveis quantitativas possiveis. Cada gráfico mostra a distribuição dos dados e utiliza uma coloração para cada variável do par, permitindo uma leitura visual mais intuitiva e clara da onde as variavel se encontram e se distanciam.

### Padrões observados:

- Frutas maiores tendem a ser mais pesadas, como mostrado pela distribuição ascendente no gráfico Size vs Weight.

- A relação inversa entre tamanho e doçura é visível na dispersão entre Size e Brix, com pontos mais baixos em Brix concentrados em tamanhos maiores.

- A coloração entre vermelho e verde no gráfico pH vs Brix sugere que frutos mais doces também tendem a ser mais ácidos.

- O tempo de colheita mostra influência sobre o tamanho e peso, mas não necessariamente sobre a doçura.

#Variáveis Qualitativas e Mistas
"""

#Quantidade de laranjas por cor
plt.figure(figsize=(10, 6))
sns.countplot(y='Color', data=df, order=df['Color'].value_counts().index, palette='viridis')
plt.title('Contagem de Laranjas por Cor')
plt.xlabel('Contagem')
plt.ylabel('Cor')
plt.tight_layout()
plt.savefig('countplot_color.png')

# Ajustar estilo
sns.set(style="whitegrid", palette="muted", font_scale=1.1)

# boxplot de Qualidade por Cor
plt.figure(figsize=(10,6))
sns.boxplot(data=df, x="Color", y="Quality (1-5)", palette="Set2")

# Visualização
plt.title("Distribuição da Qualidade por Cor da Laranja")
plt.xlabel("Cor da Laranja")
plt.ylabel("Nota de Qualidade (1-5)")
plt.xticks(rotation=30)
plt.show()

"""De acordo com os 2 últimos gráficos gerados acima, nota-se que a cor predominante é "Deep Orange" com cerca de 75 laranjas (31%) do total amostrado, além disso, "Light Orange" e "Orange-Red" aparecem em boa quantidade (~65 e 55) o que sugere uma boa diversidade intermediária de tons.

Laranjas de cor "Yellow-Orange" apresentaram uma frequência menor (~9 -> 3%), o que pode indicar que o dataset foi coletado priorizando tons mais especifico, talvez por que esse tipo de laranja seja menos comum no período amostrado.

Observa-se pelo box plot (Qualidade x Cor) que laranjas "Light Orange", possuem a maior variabibilidade, indicando que esta cor não é um bom preditor de qualidade (frutas com essa cor, podem ser tanto muito boas quanto muito ruins).

Laranjas com coloração "Depp Orange" e "Yellow-Orange", estão fortemente associada a qualidade alta (> 4.0)
"""

#Correlação de Doçura por Qualidade
plt.figure(figsize=(10, 6))
sns.barplot(x='Quality (1-5)', y='Brix (Sweetness)', data=df, palette='plasma')
plt.title('Média de Doçura (Brix) por Nota de Qualidade')
plt.xlabel('Qualidade (1-5)')
plt.ylabel('Média de Doçura (Brix)')
plt.tight_layout()
plt.savefig('barplot_brix_quality.png')

"""De acordo com o gráfico acima, observamos que há um tendência clara de aumento do Brix conforme a qualidade cresce, o que pode indicar que laranjas com alto brix, possuem uma  percepção de qualidade maior, além disso, a partir da nota 4.0 observa-se um aumento considerável no brix.

Observa-se ainda que laranjas com qualidade 5.0 tem a média mais alta de brix, com erro pequeno, o que reforça que as melhores laranjas são as mais doces.
"""

#Correlação de qualidade pelo peso
plt.figure(figsize=(12, 7))
sns.boxplot(x='Quality (1-5)', y='Weight (g)', data=df, palette='magma')
plt.title('Distribuição do Peso (g) por Nota de Qualidade')
plt.xlabel('Qualidade (1-5)')
plt.ylabel('Peso (g)')
plt.tight_layout()
plt.savefig('boxplot_weight_quality.png')

"""De acordo com o gráfico acima, podemos observar que laranjas com notas de qualidade mais alta tendem a ser mais leves em comparação com aquelas laranjas com qualidade inferior a 3.0 que apresenta mediana mais alta, além disso frutas com qualidade >= 4.0 apresentam uma distribuição de peso do tipo simétrica (normal),  com pesos medianos inferior a 225g, o que pode indicar que laranjas mais leve são mais consistentes em qualidade.

Frutas com qualidade 1, 2, 2.5 e 3.5 apresentam maior variabilidade em sua distribuição de peso, com assimetria a esquerda, indicando uma maior concentração de fruta com maior peso, porém menor qualidade.

"""

# #Correlação de acidez com manchas
# plt.figure(figsize=(20, 6))
# sns.boxplot(x='Blemishes (Y/N)', y='pH (Acidity)', data=df, palette='crest')
# plt.title('Distribuição da Acidez (pH) por Presença de Manchas')
# plt.xlabel('Presença de Manchas (Y/N)')
# plt.xticks(rotation=45, ha='right')
# plt.ylabel('pH (Acidez)')
# plt.tight_layout()
# plt.savefig('boxplot_ph_manchas.png')
# print("[OK] Gráfico 'boxplot_ph_manchas.png' foi salvo.")

"""Nota-se pelo gráfico acima que laranhas com manchas do tipo "Minor", "Sunburn", "Split Skin" e "Minor Insect Damage" possuem uma maior variablidade no pH, indicando que acidez dessa fruta é menos previsível.

Laranjas com manchas classificadas como "Sunburn" possuem valores de pH mais concentrados ~4.1, o que pode indicar uma fruta com qualidade inferior (menos saborosa).

Nota-se ainda que laranjas classificadas como sem manchas "N" possuem uma acidez mais controlada e previsível variando seu pH entre 3.15 e 3.65, enquanto que laranjas com manchas, possuem uma maior variabilidade de pH, indicando assim que frutas sem manchas podem ser consideradas de melhor qualidade.



"""

#Correlação da qualidade com manchas
df['Quality_Rounded'] = df['Quality (1-5)'].round().astype(int)
tabela_cruzada = pd.crosstab(df['Quality_Rounded'], df['Blemishes (Y/N)'])

print("\n--- Tabela Cruzada (Qualidade Arredondada vs. Manchas) ---")
print(tabela_cruzada)
print("----------------------------------------------------------")

# Visualizando a tabela cruzada com um mapa de calor
plt.figure(figsize=(10, 7))
sns.heatmap(tabela_cruzada, annot=True, cmap='YlGnBu', fmt='d')
plt.title('Mapa de Calor: Qualidade vs. Presença de Manchas')
plt.xlabel('Presença de Manchas (Y/N)')
plt.ylabel('Qualidade (Arredondada)')
plt.tight_layout()
plt.savefig('tabela_cruzada_heatmap_qualidade_manchas.png')
print("[OK] Gráfico 'tabela_cruzada_heatmap_qualidade_manchas.png' foi salvo.")

# df.head()

# Ajustar estilo
# sns.set(style="whitegrid", palette="muted", font_scale=1.1)

# # boxplot de Qualidade por presença de manchas
# plt.figure(figsize=(25,6))
# sns.boxplot(data=df, x="Blemishes (Y/N)", y="Quality (1-5)", palette="Set2")

# # Visualização
# plt.title("Distribuição da Qualidade por presença de mancha")
# plt.xlabel("presença de mancha")
# plt.ylabel("Nota de Qualidade (1-5)")
# plt.xticks(rotation=30)
# plt.show()

"""Nota-se pelo mapa de calor acima que a maior concentração de frutas (61%) está sem manchas (N), sendo que 78% das frutas sem manchas possuem qualidade >= 4.0, o que reforça ainda mais a hipótese de que frutas com maior percepção de qualidade são aquelas identificadas sem manchas (N).

Laranjas com presença de algum tipo de mancha tenden a se distribuir mais entre qualidades 2,3 e 4, raramente chegando a 5.

Frutas com manchas do tipo "Scars" e "Sunburn Patch" que foram as de maior ocorrência, apresentam qualidade entre 3 e 4, o que pode indicar uma qualidade intermediária.

Frutas com manchas por mofo (Mold Spot) e queimaduras de sol profundas (Sunburn) se mostraram com menores qualidades, enquanto que frutas com manchas por cicatrizes e outros danos ainda apresentam uma qualidade aceitável, mas raramente de qualidade > 4.0.

#Análise Multivariada
"""

# @title Matriz de correlação - Variáveis qualitativa ordinal e quantitativa contínua e discreta
corr = df.corr(numeric_only=True)
sns.heatmap(corr, annot=True, cmap="coolwarm")

df.describe()

#@title Gráfico de dispersão de duas variáveis com relação à qualidade
sns.pairplot(df, hue='Quality (1-5)')
plt.suptitle("Gráfico de dispersão das variáveis", y=1.02)
plt.savefig('pair_plot.png')
plt.show()

# Análise de variáveis: Brix x pH x Qualidade
# sns.set(style="whitegrid")

# plt.figure(figsize=(10, 6))
# sns.scatterplot(
#     data=df,
#     x="Brix (Sweetness)",
#     y="pH (Acidity)",
#     size="Quality (1-5)",
#     hue="Quality (1-5)",
#     palette="viridis",
#     sizes=(20, 300),
#     alpha=0.9,
#     edgecolor="w"
# )

# plt.title("Análise Multivariada: Brix x pH x Quality")
# plt.show()

"""De acordo com o gráfico acima, temos:

*   **Tendência geral**: Existe uma tendência de alta qualidade associada a valores mais altos de brix, ou seja, quanto mais doce a fruta, maior a probabilidade de identificarmos uma percepção de qualidade alta.

*   **Relação entre pH e qualidade**: As laranjas com qualidade mais alta aparecem em sua grande maioria com pH mais baixo (~2,8 - 3,4), o que pode indicar que uma acidez moderada-baixa combina melhor com uma fruta tida como de maior qualidade.

*  Interpretação prática: Para melhorar a qualidade da fruta é provável que se deva buscar uma combinação de maior brix e acidez moderada-baixa.
"""

# Análise de variáveis: Tamanho x Peso x Tempo de colheita
#sns.set(style="whitegrid")

#plt.figure(figsize=(10, 6))
#sns.scatterplot(
    #data=df,
    #x="Size (cm)",
    #y="Weight (g)",
    #size="HarvestTime (days)",
    #hue="HarvestTime (days)",
    #palette="viridis",
    #sizes=(20, 300),
    #alpha=0.9,
    #edgecolor="w"
#)

#plt.title("Análise Multivariada: Tamanho x Peso x Tempo de colheita")
#plt.show()

"""De acordo com o gráfico acima, temos:

*   **Têndencia geral**: Parece existir uma relação entre tempo de colheita e maturação da fruta, de forma que, frutas colhidas mais tarde tendem a ser maiores e mais pesadas, o que sugere que o tempo de crescimento impacta diretamente a qualidade e massa da fruta.

*  Distribuição do tempo de colheita: Frutas muito pequenas tendem a ter tempos de colheita menores, indicando que laranjas menores podem ter sido colhidas mais cedo, talvez por questões de maturação, manejo ou problemas fitossanitários (Greening, Pinta Preta, Leprose entre outros).

"""

# Análise de variáveis: Brix x Tempo de Colheita x Qualidade
#sns.set(style="whitegrid")

#plt.figure(figsize=(10, 6))
#sns.scatterplot(
    #data=df,
    #x="HarvestTime (days)",
    #y="Brix (Sweetness)",

    #size="Quality (1-5)",
    #hue="Quality (1-5)",
    #palette="viridis",
    #sizes=(20, 300),
    #alpha=0.9,
    #edgecolor="w"
#)

#plt.title("Análise Multivariada: Brix x Tempo de colheita x Qualidade")
#plt.show()

"""Observa-se que pontos maiores e mais claros e portanto com maior qualidade aparecem mais em tempos de colheita entre 10 - 18 dias, com brix variando entre 10 - 16. Isso pode indicar que esta janela temporal pode gerar frutos de melhor qualidade.

Colher entre 10 - 18 dias provavelmente maximiza a qualidade e doçura da fruta. Colheitas muito precoces ou muito tardias tendem a gerar frutas com qualidade inferior.

"""

# Análise de variáveis: Softness x pH x Qualidade
#sns.set(style="whitegrid")

#plt.figure(figsize=(10, 6))
#sns.scatterplot(
    #data=df,
    #x="pH (Acidity)",
    #y="Softness (1-5)",

    #size="Quality (1-5)",
    #hue="Quality (1-5)",
    #palette="viridis",
    #sizes=(20, 300),
    #alpha=0.9,
    #edgecolor="w"
#)

"""Observa-se pelos 2 últimos gráficos acima que pontos com maior qualidade parecem estar mais concentrados em pH até 3.6 e maciez até 3.0, isso sugere que frutas com pH moderado e boa maciez apresentam em média maior qualidade.

Há pontos com alta maciez (>4.0) mas qualidade baixa, indicando que pH tambem é um determinante crítico da qualidade da fruta e portanto a variável maciez por si só não é um bom preditor de qualidade.

# 📊 Análise de Correlação da Qualidade da Laranja

---

## 🍊 Principais Insights sobre Qualidade

O fator que mais influencia a **Qualidade (1-5)** é o **Brix**. O **tempo de colheita** também é relevante, mas tende a reduzir a qualidade.

### 1. Brix é o Fator Mais Forte  
- **Brix (doçura)** tem a correlação positiva mais alta com a Qualidade ($0,63$). Isso indica que o nível de doçura é o atributo mais importante.

### 2. Tempo de Colheita Impacta Negativamente  
- **HarvestTime (dias)** tem a segunda correlação mais forte, mas negativa ($-0,47$).  
- Isso indica que colher mais tarde está ligado a uma queda na qualidade.
- Existe um período ideial para o colheita, aproximadamente 10 a 18 dias.

### 3. Frutas Menores/Leves Tendem a Ter Qualidade Maior  
- **Size (cm)** e **Weight (g)** têm correlação negativa fraca com Qualidade ($-0,24$).  
- Pequenas diferenças sugerem que frutas ligeiramente menores ou mais leves podem ser percebidas como de qualidade melhor.

### 4. Equilíbrio é Importante
- Além da doçura, é essencial ter um equilíbrio entre **Acidez(pH)** e **textura(maciez)**.
- Laranjas de alta qualidade não são excessivas em ambas categorias.

---

## 🧪 Hipóteses para Explorar

**Hipótese 1:** Tempo de colheita afeta qualidade via Brix.  
- *HarvestTime* tem correlação negativa com Qualidade ($-0,47$) e com Brix ($-0,33$).  
- Após certo ponto, esperar mais tempo não aumenta o Brix e pode degradar compostos importantes para a qualidade. Há uma janela ideal de colheita.

**Hipótese 2:** Acidez e textura afetam qualidade.  
- *pH (Acidity)* ($-0,32$) e *Softness (1-5)* ($-0,30$) têm correlação negativa moderada com Qualidade.  
- Consumidores tendem a preferir laranjas menos ácidas e mais firmes. Frutas muito macias podem indicar maturação excessiva ou danos.

---

## ✅ Recomendações

Para melhorar a qualidade da laranja:  
1. Priorizar o aumento do **Brix (doçura)**.  
2. Definir o ponto ideal de colheita para evitar perda de qualidade.

**Objetivo:**
- Colher a laranja quando ela atinge o pico de **Doçura(Brix)**, antes que a laranja degrade e afete o seu sabor.

> Priorizar apenas tamanho ou atrasar a colheita pode reduzir a qualidade final.

---
📊 ENTREGA 02
---
"""

# 1.1 - Entendimento inicial da base
#df.info()
#df.describe()
#df.head()

# resultado : Não foram identificados valores ausentes, portanto não foi necessário aplicar técnicas de imputação.

# 1.2 Codificação de variáveis qualitativas

#print("Colunas Antes:", df.shape) # Verificando quantas colunas tinhamos antes da codificação (Aplicado somente a coluna categóricas)
#df_encoded = pd.get_dummies(df, columns=["Color", "Variety", "Blemishes (Y/N)"], drop_first=True) # Identificação de colunas categóricas e codificação para TRUE/FALSE
#print("Colunas Depois:", df_encoded.shape) # Verificando quantas colunas temos após codificação (O número de linhas (241) deve se manter)
#df_encoded = df_encoded.astype(int) # Convertendo TRUE/FALSE para 0/1 que é o ideal para modelos de Machine Learning
#df_encoded.head() # Visualização das primeiras 5 linhas do novo dataframe gerado (já codificado)

# Verificação se ainda existe alguma outra coluna categórica.
#df_encoded.select_dtypes(include='object').columns

# Resultado -> Não existe e a base esta pronta para normalização

# 1.3 Normalização de variáveis quantitativas (Colocando as variáveis na mesma escala para evitar eventuais distorção nos modelos de ML)

#from sklearn.preprocessing import StandardScaler

# Selecionando somente colunas numéricas do novo dataframe (já codificado)
#numeric_cols = df_encoded.select_dtypes(include=['int64', 'float64']).columns


# Removendo a variável alvo (target) da normalização
#targets = ['Quality (1-5)', 'Quality_Rounded'] # se formos usar modelo de classificação, então considero que melhor usarmos como target a coluna "Quality_Rounded", caso modelo de regressão então podemos usar "Quality (1-5)"

#numeric_cols = [col for col in numeric_cols if col not in targets]


# Criando o scaler (padronizando as  variáveis)
#scaler = StandardScaler()

# Aplicando normalização -> fit_transform ajusta o scaler aos dados e transforma as colunas
#df_encoded[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])

#df_encoded.head() # Visualizado o data frame já pronto para ser consumido em modelo de ML

# 1.4 Tratando outliers (valores discrepantes)

## visualizando eventuais outliers
#import matplotlib.pyplot as plt
#import seaborn as sns

# Selecionando colunas numéricas contínuas para vizualização
#plt.figure(figsize=(15,8))
#sns.boxplot(data=df_encoded[numeric_cols].melt(), x='variable', y='value')
#plt.xticks(rotation=90)
#plt.show()

#print(df_encoded.to_string()) # Visualizando todo o data frame

# Fazendo a remoção dos outliers
#from scipy import stats
#df_encoded = df_encoded[(np.abs(stats.zscore(df_encoded[numeric_cols])) < 3).all(axis=1)]

# Visualizando o dataframe após identificação e remoção dos outliers
#plt.figure(figsize=(15,8))
#sns.boxplot(data=df_encoded[numeric_cols].melt(), x='variable', y='value')
#plt.xticks(rotation=90)
#plt.show()

# @title Importando bibliotecas do Scikit-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# Pré-processamento
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import (
    train_test_split, cross_validate,
    RandomizedSearchCV, ShuffleSplit
)
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Modelos
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# Utilitários para suprimir avisos
import warnings
from sklearn.exceptions import ConvergenceWarning

df = pd.read_csv('https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv')
df

# @title Processando 'Blemishes (Y/N)'
print("Valores únicos antes da transformação:")
print(df['Blemishes (Y/N)'].value_counts().head())

# Criar a nova coluna binária 'Blemishes'
df['Blemishes'] = df['Blemishes (Y/N)'].apply(lambda x: 0 if 'N' in x else 1)

print("\nValores únicos depois da transformação:")
print(df['Blemishes'].value_counts())

# @title Definindo X, y e separando Treino/Teste

# Convertendo a coluna alvo para inteiro
df['Quality (1-5)'] = df['Quality (1-5)'].astype(int)

# Definindo X (features) e y (alvo)
X = df.drop(['Quality (1-5)', 'Blemishes (Y/N)'], axis=1)
y = df['Quality (1-5)']

# Separar em treino e teste (estratificado pela variável alvo 'y')
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print(f"Tamanho de X_train: {X_train.shape}")
print(f"Tamanho de X_test: {X_test.shape}")

# @title Definindo o ColumnTransformer

# 1. Definir colunas numéricas
numeric_features = [
    'Size (cm)', 'Weight (g)', 'Brix (Sweetness)', 'pH (Acidity)',
    'Softness (1-5)', 'HarvestTime (days)', 'Ripeness (1-5)', 'Blemishes'
]

# 2. Definir colunas categóricas
categorical_features = ['Color', 'Variety']

# 3. Criar o pré-processador (ColumnTransformer)
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
    ],
    remainder='passthrough'
)

"""### Usamos o Standardascaler e OneHotEncoder, um para os dados numéricos e outro para os dados categóricos, respectivamente. Devido às características dos dados, pois é mais simples e eficiente apenas dividir os dados em duas categorias, onde os numéricos tem um objetivo em comum que é o escalonamento. Enquanto os dados categóricos, apenas os tranformamos em números."""

# @title Definindo Modelos e Grades de Parâmetros

# 1. Definindo os modelos
models = {
    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),
    'DecisionTree': DecisionTreeClassifier(random_state=42),
    'RandomForest': RandomForestClassifier(random_state=42),
    'SVC': SVC(probability=True, random_state=42),
    'KNN': KNeighborsClassifier(),
    'GradientBoosting': GradientBoostingClassifier(random_state=42)
}

# 2. Definindo as grades de parâmetros para otimização
param_grids = {
    'LogisticRegression': {
        'classifier__C': [0.1, 1.0, 10, 100],
        'classifier__solver': ['liblinear', 'lbfgs']
    },
    'DecisionTree': {
        'classifier__max_depth': [None, 10, 20, 30],
        'classifier__min_samples_leaf': [1, 2, 4],
        'classifier__min_samples_split': [2, 5, 10]
    },
    'RandomForest': {
        'classifier__n_estimators': [100, 200, 300],
        'classifier__max_depth': [None, 10, 20],
        'classifier__min_samples_leaf': [1, 2, 4]
    },
    'SVC': {
        'classifier__C': [0.1, 1, 10],
        'classifier__gamma': ['scale', 'auto'],
        'classifier__kernel': ['rbf', 'linear']
    },
    'KNN': {
        'classifier__n_neighbors': [3, 5, 7, 9, 11]
    },
    'GradientBoosting': {
        'classifier__n_estimators': [100, 200, 300],
        'classifier__learning_rate': [0.01, 0.1, 0.2],
        'classifier__max_depth': [3, 5, 7]
    }
}

"""**Regressão Logística:** Modelo base, se os modelos complexos não forem melhor que ele, então a relação entre as features é simples e linear, assim como o modelo.

**KNN:** Modelo baseado em instâncias, ideal para detectar relções complexas que modelos lineares não enxergariam.

**Árvore de Decisão:** É fácil de interpretar e entender como funciona as decisões do modelo, além de ser a base dos modelos ensemble.

**Floresta Aleatória:** É um modelo robusto que costuma ter bons desempenhos, onde ele constroi várias árvores, com amostras aleatórias, dos dados e das features, no final é decidido qual a melhor árvore.

**GBM:** É um modelo de muito desempenho em dados tabulares, que se diferencia da floresta aleatória pelo fato de construir árvores para corrigir problemas da anterior, ou seja, teoricamente a cada árvore o modelo melhora.

**SVC:** É um modelo diferente que usa uma abordagem geométrica baseada em kernels, tentando encontrar o "hiperplano" que separa as classes com maior distância possível.
"""

# @title Executando a Otimização (RandomizedSearchCV)

best_models = {}

# Suprimir avisos de convergência durante a otimização
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning)

    for model_name in models.keys():
        print(f"Otimizando {model_name}...")

        # Criar o pipeline completo
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', models[model_name])
        ])

        # Obter a grade de parâmetros
        param_dist = param_grids[model_name]

        if not param_dist:
            best_models[model_name] = pipeline
            print(f"{model_name} não possui hiperparâmetros para otimizar.")
            continue

        search = RandomizedSearchCV(
            pipeline,
            param_dist,
            n_iter=10,
            cv=5,
            scoring='accuracy',
            random_state=42,
            n_jobs=-1,
            error_score='raise'
        )

        # Executar a busca nos dados de treino
        search.fit(X_train, y_train)

        # Salvar o melhor pipeline encontrado
        best_models[model_name] = search.best_estimator_
        print(f"Melhor acurácia (CV interna) para {model_name}: {search.best_score_:.4f}")

print("\n--- Otimização concluída ---")
print(f"Modelos otimizados armazenados: {list(best_models.keys())}")

# @title Executando a Validação Monte Carlo

# 1. Definir a estratégia de Validação Cruzada Monte Carlo
cv_strategy = ShuffleSplit(n_splits=30, test_size=0.2, random_state=42)

# 2. Definir as métricas
scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc_ovr']

# 3. Dicionário para armazenar resultados
model_results = {}

# 4. Loop de avaliação
print("Executando Validação Monte Carlo (ShuffleSplit)...")
for model_name, optimized_pipeline in best_models.items():
    print(f"Avaliando {model_name} (otimizado)...")

    # Executar o cross-validate usando o pipeline otimizado e a estratégia ShuffleSplit
    scores = cross_validate(
        optimized_pipeline,
        X_train,
        y_train,
        cv=cv_strategy,
        scoring=scoring_metrics,
        n_jobs=-1
    )
    model_results[model_name] = scores

print("\n--- Validação Monte Carlo concluída ---")

# @title Convertendo resultados para DataFrame

results_list = []
for model_name, scores in model_results.items():
    for metric in scoring_metrics:
        score_key = f'test_{metric}'
        if score_key in scores:
            for score_value in scores[score_key]:
                results_list.append({
                    'modelo': model_name,
                    'Métrica': metric,
                    'Score': score_value
                })

results_df = pd.DataFrame(results_list)

print("Resultados da Validação Monte Carlo (primeiras linhas):")
display(results_df)

metrics_to_plot = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']
plot_data_filtered = results_df[results_df['Métrica'].isin(metrics_to_plot)]

pivot_table = pd.pivot_table(
    plot_data_filtered,
    values='Score',
    index='Métrica',
    columns='modelo',
    aggfunc=['mean', 'std']
)

# Reordenar as linhas (métricas) para ficarem na ordem desejada
pivot_table = pivot_table.reindex(metrics_to_plot)

pd.options.display.float_format = '{:.4f}'.format

print("\nTabela Pivô (Média e Desvio Padrão):")
print(pivot_table)

# @title Visualização dos Resultados (Gráfico de Barras)

# Criar o gráfico (Catplot com kind='bar')
g = sns.catplot(
    data=plot_data_filtered,
    x='modelo',
    y='Score',
    col='Métrica',
    kind='bar',
    height=6,
    aspect=1.2,
    palette='viridis',
    order=sorted(plot_data_filtered['modelo'].unique())
)

# Ajustes de título e rótulos
g.fig.suptitle("Comparação de Desempenho (Validação Monte Carlo, 30 iterações)", y=1.03, fontsize=16)
g.set_titles("{col_name}", size=14)
g.set_axis_labels("Modelo (Otimizado)", "Pontuação Média (Score)", size=12)
g.set_xticklabels(rotation=30, ha='right')

# Ajustar o layout
plt.tight_layout()

#Salvar a imagem
image_filename = "model_comparison_monte_carlo_bars.png"
plt.savefig(image_filename, bbox_inches='tight', dpi=150)

print(f"Gráfico de comparação (barras) salvo em '{image_filename}'")
plt.show()

# @title Visualização dos Resultados (Boxplot)

# Criar o gráfico (Catplot com kind='box')
g = sns.catplot(
    data=plot_data_filtered,
    x='modelo',
    y='Score',
    col='Métrica',
    kind='box',
    height=6,
    aspect=1.2,
    palette='viridis',
    order=sorted(plot_data_filtered['modelo'].unique())
)

# Ajustes de título e rótulos
g.fig.suptitle("Comparação de Desempenho (Validação Monte Carlo, 30 iterações)", y=1.03, fontsize=16)
g.set_titles("{col_name}", size=14)
g.set_axis_labels("Modelo (Otimizado)", "Pontuação (Score)", size=12)
g.set_xticklabels(rotation=30, ha='right')

# Ajustar o layout
plt.tight_layout()

# Salvar a imagem
image_filename = "model_comparison_monte_carlo.png"
plt.savefig(image_filename, bbox_inches='tight', dpi=150)

print(f"Gráfico de comparação salvo em '{image_filename}'")
plt.show()

# @title Comparação de Modelos como as melhores resultados
results_list = []
for model_name, scores in model_results.items():
    for metric in scoring_metrics:
        score_key = f'test_{metric}'
        if score_key in scores:
            for score_value in scores[score_key]:
                results_list.append({
                    'modelo': model_name,
                    'Métrica': metric,
                    'Score': score_value
                })
results_df = pd.DataFrame(results_list)

max_scores = results_df.groupby(['modelo', 'Métrica'])['Score'].max().unstack()
max_scores = max_scores[scoring_metrics]

print("\n--- Maiores Scores (Validação Monte Carlo) por Modelo Otimizado ---")
print(max_scores)

# 1. Identificar os 3 melhores modelos com base no f1_macro MÁXIMO
best_model_names_max = max_scores.sort_values(by='f1_macro', ascending=False).index[:3].tolist()

print("\n--- Análise do Top 3 (Baseado no Score Máximo) ---")
print(f"Os 3 melhores modelos (baseado no f1_macro máximo) são: {', '.join(best_model_names_max)}")

# 2. Filtrar a tabela de médias e o DataFrame completo de resultados
top_max_scores = max_scores.loc[best_model_names_max]
# Usamos o 'results_df' original para os boxplots
top_results_df = results_df[results_df['modelo'].isin(best_model_names_max)]

print("\n--- Maiores Scores (Top 3 Modelos) ---")
print(top_max_scores)

# 3. Gerar novo gráfico de boxplot focado nos 3 melhores
# O boxplot ainda mostra a distribuição completa (as 30 iterações),
# o que é bom para vermos a variabilidade.
metrics_to_plot = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']
plot_data_filtered = top_results_df[top_results_df['Métrica'].isin(metrics_to_plot)]

g = sns.catplot(
    data=plot_data_filtered,
    x='modelo',
    y='Score',
    col='Métrica',
    kind='box',
    height=6,
    aspect=1.0,
    palette='viridis',
    order=best_model_names_max
)

# Título e rótulos
g.fig.suptitle("Comparação de Desempenho (Top 3 Modelos - Scores Máximos)", y=1.03, fontsize=16)
g.set_titles("{col_name}", size=14)
g.set_axis_labels("Modelo (Otimizado)", "Pontuação (Score)", size=12)
g.set_xticklabels(rotation=0)

plt.tight_layout()

# Salvar a imagem final
image_filename = "top_3_model_max_score_comparison.png"
plt.savefig(image_filename, bbox_inches='tight', dpi=150)

print(f"\nGráfico de comparação do Top 3 (baseado em max score) salvo em '{image_filename}'")

"""**Acurácia:** É a métrica mais intuitiva, responde simplesmente qual a porcentagem de laranjas que o modelo acertou a qualidade.

**Precisão Macro:** É importante saber o quanto o modelo previu de falsos positivos, nesse caso utilizamos o macro para saber a precisão de cada classe e fazer uma média simples, dessa maneira se o modelo for muito bom em prever nota 5 que é mais comum, mas muito ruim em prever nota 1 que é mais incomum, então a média será baixa, ou seja, penalizando por ignorar a classe rara.

**Recall Macro:** Assim como a precisão, mas agora para os falsos negativos, ou seja, de todas as laranjas que eram nota 1, de quantas conseguiu identificar corretamente? Ele responde se o modelo tem dificuldade em encontrar classes menos frequêntes.

**F1-Score Macro:** É uma média entre os dois casos anteriores, ou seja, se está métrica estiver alta, fala que o modelo é bom em identificar todas as classes não apenas as mais comuns.

**ROC AUC One-vs-Rest:** Ela obsera a capacidade da separação do modelo. Medindo a habilidade do modelo de dar um pontuação de probabiliade mais alta para a classe correta do que para as demais, como ROC AUC é binário o One-vs-Rest adapta essa métrica para um caso de multi-classe, dessa maneira ela testa cada classe em comparação ao resto e faz uma média.

---
Análise dos resultado e Conclusões
---
"""

import matplotlib.image as mpimg
img1 = mpimg.imread('model_comparison_monte_carlo.png')
img2 = mpimg.imread('top_3_model_max_score_comparison.png')
plt.figure(figsize=(17, 12))
plt.imshow(img1)

plt.figure(figsize=(15, 10))
plt.imshow(img2)

"""1º O melhor modelo é o SVC: Se fosse para escolher um modelo para colocar em produção com este dataset, seria o SVC. Ele provou ser o mais equilibrado, com o melhor f1_macro, sendo superior tanto em precisão quanto em capacidade de encontrar classes raras.

2º Por que a Regressão Logística teve uma acurácia tão alta: O desempenho surpreendentemente forte de um modelo linear (LogisticRegression) e o desempenho decepcionante de um modelo complexo (GradientBoosting) são sintomas clássicos de um conjunto de dados pequeno. Os modelos complexos não têm dados suficientes para melhorar o seu desempenho.

3º Podemos inferir que se tivessemos dados mais robustos, uma quantidade mais alta, provavelente modelos como o floresta aleatória e o Gradient Boosting produzissem resultados melhores, porém com os dados que temos o mais equilibrado mesmo é o SVC.

4º Quando olhamos para os valores máximos, vemos que a regrassão logística obteve a maior acurácia, isso mostrar que em alguma combinação de hiperparâmetros otimiza seu desempenho, porém ainda não obteve outras métricas melhores que o SVC.

5º Por que mesmo o SVC estando atrás da Regrassão Logística e do KNN, na métrica ROC AUC, ele continua sendo o melhor? Porque mesmo que KNN e Regressão Logística ainda têm precisão e recall menores que o SVC, quando analisamos os máximos, o que deixa a entender que esses dois modelos ficaram bons em diferenciar as categorias mais comuns, porém não são tão bons com as mais raras, enquanto o SVC tem um equilíbrio muito melhor. Dessa forma, se a amostra tivesse uma variabilidade maior de dados, talvez esses modelos não teriam tais números.
"""