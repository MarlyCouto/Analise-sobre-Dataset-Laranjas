# -*- coding: utf-8 -*-
"""C√≥pia de Orange - Quality Analysis Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PCQlGfqZ03aYz13gjknJY2AknzfBIRtX

---

# An√°lise Explorat√≥ria de Dados
 - Conjunto de dados: `orange_quality` (Laranja Mec√¢nica)
 - Alunos:
   - Vanessa Fermino dos Santos Cavalcante
   - Ana Marly do Couto da Silva
   - Romeu R√≥seo
   - Jos√© Ab√≠lio
---

## Prepara√ß√£o
 - Carregamento de bibliotecas
 - Configura√ß√£o de estilo dos gr√°ficos
 - Leitura do conjunto de dados
"""

# @title Carregando bibliotecas

import itertools
import pandas as pd
import numpy as np
from scipy import stats as st
from matplotlib import pyplot as plt
import seaborn as sns
from IPython.display import Markdown

# sns.set_style("whitegrid")
sns.set_theme(style="whitegrid", palette="colorblind")

palette_dict = {
    'day': 'Set1',   # Exemplo de paleta para 'day'
    'time': 'Dark2', # Exemplo de paleta para 'time'
    'smoker': 'coolwarm', # Paleta para 'smoker'
    'sex': 'Pastel1',   # Paleta para 'sex'
}

# @title Leitura do conjunto de dados
df = pd.read_csv(
    "https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv"
)
df.head()

"""# Informa√ß√µes iniciais"""

display(Markdown("### Primeiras linhas"))
display(df.head())

display(Markdown("### Ultimas linhas"))
display(df.tail())

display(Markdown("### Informa√ß√£o das vari√°veis"))
df.info()

display(Markdown("### Quantidade de valores √∫nicos"))
df.nunique()

"""# Dados faltantes"""

df.isnull().sum()

"""A partir das informa√ß√µes iniciais, podemos dizer que:

*   O conjunto de dados tem 241 unidades amostrais com 11 vari√°veis(columns)
*   N√£o h√° valores ausentes em nenhuma das colunas.
*   Todas as colunas s√£o do tipo num√©rico (inteiro ou float), exceto pelas colunas "Color", "Variety" e "Blemishes (Y/N)" que s√£o do tipo objeto (texto).


*   Classifica√ß√£o das vari√°veis:


    *  Quantitativa cont√≠nua: Size (cm), Weight (g),Brix (Sweetness), pH (Acidity)
    *   Quantitativa discreta: HarvestTime (days)
    *   Qualitativa nominal: Color, Variety, Blemishes (Y/N), Quality (1‚Äì5)
    *   Qualitativa ordinal: Softness (1‚Äì5), Ripeness (1‚Äì5)


"""

# @title Dicion√°rio de dados
df_dict = pd.DataFrame([
    {
        "variavel": "Size (cm)",
        "descricao": "Medida em cent√≠metros.",
        "tipo": "Quantitativa",
        "subtipo": "cont√≠nua",
    },
    {
        "variavel": "Weight (g)",
        "descricao": "Medida em gramas.",
        "tipo": "Quantitativa",
        "subtipo": "cont√≠nua",
    },
    {
        "variavel": "Brix (Sweetness)",
        "descricao": "Grau de do√ßura, normalmente em escala cont√≠nua (¬∞Brix).",
        "tipo": "Quantitativa",
        "subtipo": "cont√≠nua",
    },
    {
        "variavel": "pH (Acidity)",
        "descricao": "Escala cont√≠nua de acidez.",
        "tipo": "Quantitativa",
        "subtipo": "cont√≠nua",
    },
    {
        "variavel": "Softness (1-5)",
        "descricao": "Escala de 1 a 5, reflete percep√ß√£o de maciez/textura da fruta.",
        "tipo": "Qualitativa",
        "subtipo": "ordinal",
    },
    {
        "variavel": "HarvestTime (days)",
        "descricao": "Dias at√© a colheita (contagem inteira).",
        "tipo": "Quantitativa",
        "subtipo": "discreta",
    },
    {
        "variavel": "Ripeness (1-5)",
        "descricao": "Grau de matura√ß√£o em escala de 1 a 5.",
        "tipo": "Qualitativa",
        "subtipo": "ordinal",
    },
    {
        "variavel": "Color",
        "descricao": "Cor da fruta.",
        "tipo": "Qualitativa",
        "subtipo": "nominal",
    },
    {
        "variavel": "Variety",
        "descricao": "Nome da variedade da fruta",
        "tipo": "Qualitativa",
        "subtipo": "nominal",
    },
    {
        "variavel": "Blemishes (Y/N)",
        "descricao": "Presen√ßa ou n√£o de defeitos",
        "tipo": "Qualitativa",
        "subtipo": "nominal",
    },
    {
        "variavel": "Quality (1-5)",
        "descricao": "Avalia√ß√£o de qualidade em escala de 1 a 5",
        "tipo": "Qualitativa",
        "subtipo": "ordinal",
    }
])
df_dict

"""# An√°lise univariada

# Resumo estat√≠stico
"""

print("--- Verificando os tipos de dados das colunas ---")
df.info()

# @title Resumo estat√≠stico

display(Markdown("### Vari√°veis qualitativas"))
print(df.describe(include='object'))

display(Markdown("### Vari√°veis quantitativas"))
print(df.describe())

"""# Resumo da An√°lise Inicial:

Tamanho e Peso: O tamanho m√©dio das laranjas √© de 7.84 cm e o peso m√©dio √© de 205.12 gramas.

Do√ßura e Acidez: A do√ßura (Brix) e a acidez (pH) parecem estar dentro de uma faixa consistente, com m√©dias de 10.90 e 3.47, respectivamente.

Qualidade: A qualidade das laranjas, em uma escala de 1 a 5, tem uma m√©dia de 3.81, indicando que, no geral, as laranjas deste conjunto de dados s√£o de boa qualidade.

Variedades e Cores: As variedades mais comuns s√£o "Cara Cara" e "Star Ruby". A cor predominante √© "Deep Orange".

Manchas: A maioria das laranjas n√£o apresenta manchas ("Blemishes (Y/N)" = N).

# Distribui√ß√£o de Vari√°veis

# Vari√°veis Qualitativas
"""

# Identificar vari√°veis qualitativas
variaveis_qualitativas = df.select_dtypes(include=['object']).columns.tolist()


# Remover a vari√°vel 'Color' da lista de vari√°veis qualitativas
if 'Color' in variaveis_qualitativas:
    variaveis_qualitativas.remove('Color')

print("\n--- An√°lise Univariada: Vari√°veis Qualitativas (exceto 'Color') ---")

# Tabelas de Frequ√™ncia
for var in variaveis_qualitativas:
    print(f"\nTabela de Frequ√™ncia para a vari√°vel '{var}':")
    print(df[var].value_counts())
    print("-" * 30)

# Visualiza√ß√µes (Gr√°ficos de Barras)
num_qual_vars = len(variaveis_qualitativas)

# Apenas criar gr√°ficos se houver vari√°veis qualitativas restantes
if num_qual_vars > 0:
    fig, axes = plt.subplots(figsize=(10, 5 * num_qual_vars), ncols=1, nrows=num_qual_vars) # Ajustado para plots verticais
    if num_qual_vars == 1:
        axes = [axes]
    fig.suptitle('Distribui√ß√£o das Vari√°veis Qualitativas', fontsize=16)

    for i, variavel in enumerate(variaveis_qualitativas):
        order = df[variavel].value_counts().index
        ax = sns.countplot(data=df, y=variavel, ax=axes[i], order=order, palette='viridis', alpha=0.8)
        ax.bar_label(ax.containers[0], fmt="%d", color="black", label_type="edge", fontweight='bold', padding=5)
        ax.set(title=f"Distribui√ß√£o de '{variavel}'", xlabel="Contagem", ylabel="")
        for side in ["bottom","top", "right"]:
            ax.spines[side].set_visible(False)
        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: int(x)))

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.savefig('qualitative_analysis.png')
    print("\nGr√°ficos das vari√°veis qualitativas salvos em 'qualitative_analysis.png'")
else:
    print("\nNenhuma vari√°vel qualitativa para analisar ap√≥s a remo√ß√£o de 'cor'.")

"""# Vari√°veis Quantitativas"""

# Identificar vari√°veis quantitativas
variaveis_quantitativas = df.select_dtypes(include=['number']).columns.tolist()

print("--- An√°lise Univariada: Vari√°veis Quantitativas ---")
print("\nEstat√≠sticas Descritivas:")
print(df[variaveis_quantitativas].describe())

# Visualiza√ß√µes (Histogramas e Boxplots)
num_quant_vars = len(variaveis_quantitativas)
fig, axes = plt.subplots(nrows=num_quant_vars, ncols=2, figsize=(12, num_quant_vars * 4))
fig.suptitle('Distribui√ß√£o das Vari√°veis Quantitativas', fontsize=16, y=1.02)

for i, var in enumerate(variaveis_quantitativas):
    # Histograma
    sns.histplot(df[var], kde=True, ax=axes[i, 0])
    axes[i, 0].set_title(f'Histograma de {var}')
    axes[i, 0].set_xlabel('')
    axes[i, 0].set_ylabel('Frequ√™ncia')

    # Boxplot
    sns.boxplot(x=df[var], ax=axes[i, 1])
    axes[i, 1].set_title(f'Boxplot de {var}')
    axes[i, 1].set_xlabel('')

plt.tight_layout(rect=[0, 0, 1, 0.99])
plt.savefig('quantitative_analysis.png')
print("\nGr√°ficos das vari√°veis quantitativas salvos em 'quantitative_analysis.png'")

"""A an√°lise univariada nos mostra que o dataset representa um lote de laranjas de boa qualidade geral (nota m√©dia 3.81, 75% sem manchas), com sabor consistente (baixa varia√ß√£o de do√ßura), mas com tamanhos e pesos variados."""

# Lista das vari√°veis num√©ricas que queremos comparar entre as variedades
variaveis_para_analise = ['Size (cm)', 'Weight (g)', 'Brix (Sweetness)', 'pH (Acidity)']

# Criar uma figura para colocar nossos gr√°ficos
# Teremos 2 linhas e 2 colunas de gr√°ficos
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))
# Transforma a matriz de eixos 2x2 em uma lista para facilitar o loop
axes = axes.flatten()

fig.suptitle('Compara√ß√£o das Caracter√≠sticas Num√©ricas por Variedade', fontsize=18, y=1.03)

# Loop para criar um boxplot para cada vari√°vel num√©rica
for i, var_numerica in enumerate(variaveis_para_analise):
    sns.boxplot(data=df, x=var_numerica, y='Variety', ax=axes[i], palette='pastel')

    axes[i].set_title(f'Distribui√ß√£o de "{var_numerica}" por Variedade', fontsize=14)
    axes[i].set_xlabel(var_numerica, fontsize=12)
    axes[i].set_ylabel('Variedade', fontsize=12)

# Ajusta o layout para evitar que os t√≠tulos se sobreponham
plt.tight_layout()
# Salva a figura em um arquivo
plt.savefig('boxplot_horizontal_por_variedade.png')

print("\nGr√°fico comparativo de boxplots horizontais salvo em 'boxplot_horizontal_por_variedade.png'")

"""# An√°lise Bivariada

##Vari√°veis Quantitativas
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap

# Leitura do Conjunto de Dados
df = pd.read_csv(
    "https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv"
)

# Lista de vari√°veis quantitativas
variaveis_quantitativas = ['Size (cm)', 'Weight (g)', 'Brix (Sweetness)', 'pH (Acidity)', 'HarvestTime (days)']

# Matriz de correla√ß√£o
correlation_matrix = df[variaveis_quantitativas].corr()

# Exibir a matriz
print("üîó Correla√ß√£o Geral entre Vari√°veis Quantitativas:")
print(correlation_matrix)

# Criar paleta divergente: creme ‚Üí amarelo ‚Üí laranja ‚Üí marrom
colors = ["#f5f5dc", "#ffffcc", "#ffcc66", "#cc6600"]
# creme, amarelo claro, laranja, marrom

# Visualizar com mapa de calor
creme_orange_cmap = LinearSegmentedColormap.from_list("CremeOrange", colors, N=256)
sns.heatmap(
    correlation_matrix,
    annot=True,
    cmap=creme_orange_cmap,
    fmt=".2f",
    center=0,
    vmin=-0.2,
    vmax=1.0
)

plt.title('Matriz de Correla√ß√£o Quantitativa Geral')
plt.show()
plt.savefig('Matriz_corr_quant')

"""#An√°lise Geral das Correla√ß√µes entre Vari√°veis Quantitativas

A matriz de correla√ß√£o geral mostra importantes dados entre as vari√°veis f√≠sicas e qu√≠micas das frutas contidas no dataset. Embora os n√∫meros de correla√ß√£o n√£o sejam extremamente altos, alguns padr√µes interessantes podem ser encontrados:

‚Ä¢ 	**Tamanho (Size) e Peso (Weight)**:

Apresentam uma correla√ß√£o positiva moderada
(r = 0.31), indicando que frutas maiores tendem a ser mais pesadas, como esperado. Essa rela√ß√£o √© coerente com a l√≥gica f√≠sica do crescimento dos frutos.

‚Ä¢ 	**Brix (Sweetness)** que representa o grau de do√ßura:

Mostra correla√ß√£o negativa com as vari√°veis;

1. Size (r = ‚Äì0.31) e Weight (r = ‚Äì0.24), sugerindo que frutas maiores e mais
pesadas tendem a ser menos doces.

2. pH (Acidity) (r = ‚Äì0.30) indicando que frutas mais doces tendem a ser mais √°cidas ‚Äî uma rela√ß√£o interessante que pode refletir o est√°gio de matura√ß√£o ou caracter√≠sticas de cada variedade.


‚Ä¢ 	**pH (Acidity)**:

Tem correla√ß√£o positiva com Size (r = 0.33) e Weight (r = 0.30), o que pode indicar que frutas maiores apresentam menor acidez relativa.

‚Ä¢ 	**HarvestTime (days)** ou tempo at√© a colheita:

Apresenta correla√ß√µes positivas discretas com Size (r = 0.30) e Weight (r = 0.33), sugerindo que frutas colhidas mais tardiamente tendem a ser maiores e mais pesadas.

Por outro lado, sua correla√ß√£o com Brix √© negativa (r = ‚Äì0.26), o que pode indicar que o prolongamento do tempo de colheita n√£o necessariamente aumenta a do√ßura.

"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import itertools
import math
import numpy as np
from matplotlib.patches import Patch

# Leitura de Conjunto de Dados
df = pd.read_csv("https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv")

# Vari√°veis quantitativas
variaveis_quantitativas = ['Size (cm)', 'Weight (g)', 'Brix (Sweetness)', 'pH (Acidity)', 'HarvestTime (days)']

# N√∫mero de colunas
num_cols = 3
pairs = list(itertools.combinations(variaveis_quantitativas, 2))
num_rows = math.ceil(len(pairs) / num_cols)

# Dicion√°rio de cores por vari√°vel
color_map = {
    'Size (cm)': '#1f77b4',        # azul
    'Weight (g)': '#ff7f0e',       # laranja
    'Brix (Sweetness)': '#2ca02c', # verde
    'pH (Acidity)': '#d62728',     # vermelho
    'HarvestTime (days)': '#9467bd' # roxo
}

# Criar figura com subplots
fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(7 * num_cols, 5.5 * num_rows))
axes = axes.flatten()

for i, (var1, var2) in enumerate(pairs):
    # Normalizar valores para interpola√ß√£o de cor
    norm1 = (df[var1] - df[var1].min()) / (df[var1].max() - df[var1].min())
    norm2 = (df[var2] - df[var2].min()) / (df[var2].max() - df[var2].min())
    blend = (norm1 + norm2) / 2

    # Criar colormap entre as duas cores
    cmap = sns.blend_palette([color_map[var1], color_map[var2]], as_cmap=True)
    colors = cmap(blend)

    axes[i].scatter(
        df[var1],
        df[var2],
        c=colors,
        alpha=0.7,
        s=40
    )

    axes[i].set_title(f'{var1} vs {var2}', fontsize=13)
    axes[i].set_xlabel(var1, fontsize=11)
    axes[i].set_ylabel(var2, fontsize=11)
    axes[i].grid(True)

    coef = df[[var1, var2]].corr().iloc[0, 1]
    print(f"üìà Correla√ß√£o entre '{var1}' e '{var2}': {coef:.2f}")
    print("-" * 50)

# Remover eixos extras se houver
for j in range(i + 1, len(axes)):
    axes[j].axis('off')

# Espa√ßamento entre os gr√°ficos
plt.subplots_adjust(wspace=0.4, hspace=0.5)

# T√≠tulo geral
fig.suptitle('Matriz de Correla√ß√£o entre os Pares de Vari√°veis Quantitativas', fontsize=20, y=0.94)

# Legendas t√≠tulo e gr√°ficos
legend_elements = [Patch(facecolor=color_map[var], label=var) for var in variaveis_quantitativas]

fig.legend(
    handles=legend_elements,
    loc='upper center',
    bbox_to_anchor=(0.5, 0.89),
    ncol=len(variaveis_quantitativas),
    frameon=False,
    fontsize=10,
    title='Cores atribu√≠das √†s vari√°veis'
)

plt.tight_layout(rect=[0, 0, 1, 0.86])
plt.show()

"""# An√°lise Visual por Gr√°ficos de Dispers√£o

Para complementar a leitura estat√≠stica, foram gerados gr√°ficos de dispers√£o entre todos os pares de vari√°veis quantitativas possiveis. Cada gr√°fico mostra a distribui√ß√£o dos dados e utiliza uma colora√ß√£o para cada vari√°vel do par, permitindo uma leitura visual mais intuitiva e clara da onde as variavel se encontram e se distanciam.

### Padr√µes observados:

- Frutas maiores tendem a ser mais pesadas, como mostrado pela distribui√ß√£o ascendente no gr√°fico Size vs Weight.

- A rela√ß√£o inversa entre tamanho e do√ßura √© vis√≠vel na dispers√£o entre Size e Brix, com pontos mais baixos em Brix concentrados em tamanhos maiores.

- A colora√ß√£o entre vermelho e verde no gr√°fico pH vs Brix sugere que frutos mais doces tamb√©m tendem a ser mais √°cidos.

- O tempo de colheita mostra influ√™ncia sobre o tamanho e peso, mas n√£o necessariamente sobre a do√ßura.

#Vari√°veis Qualitativas e Mistas
"""

#Quantidade de laranjas por cor
plt.figure(figsize=(10, 6))
sns.countplot(y='Color', data=df, order=df['Color'].value_counts().index, palette='viridis')
plt.title('Contagem de Laranjas por Cor')
plt.xlabel('Contagem')
plt.ylabel('Cor')
plt.tight_layout()
plt.savefig('countplot_color.png')

# Ajustar estilo
sns.set(style="whitegrid", palette="muted", font_scale=1.1)

# boxplot de Qualidade por Cor
plt.figure(figsize=(10,6))
sns.boxplot(data=df, x="Color", y="Quality (1-5)", palette="Set2")

# Visualiza√ß√£o
plt.title("Distribui√ß√£o da Qualidade por Cor da Laranja")
plt.xlabel("Cor da Laranja")
plt.ylabel("Nota de Qualidade (1-5)")
plt.xticks(rotation=30)
plt.show()

"""De acordo com os 2 √∫ltimos gr√°ficos gerados acima, nota-se que a cor predominante √© "Deep Orange" com cerca de 75 laranjas (31%) do total amostrado, al√©m disso, "Light Orange" e "Orange-Red" aparecem em boa quantidade (~65 e 55) o que sugere uma boa diversidade intermedi√°ria de tons.

Laranjas de cor "Yellow-Orange" apresentaram uma frequ√™ncia menor (~9 -> 3%), o que pode indicar que o dataset foi coletado priorizando tons mais especifico, talvez por que esse tipo de laranja seja menos comum no per√≠odo amostrado.

Observa-se pelo box plot (Qualidade x Cor) que laranjas "Light Orange", possuem a maior variabibilidade, indicando que esta cor n√£o √© um bom preditor de qualidade (frutas com essa cor, podem ser tanto muito boas quanto muito ruins).

Laranjas com colora√ß√£o "Depp Orange" e "Yellow-Orange", est√£o fortemente associada a qualidade alta (> 4.0)
"""

#Correla√ß√£o de Do√ßura por Qualidade
plt.figure(figsize=(10, 6))
sns.barplot(x='Quality (1-5)', y='Brix (Sweetness)', data=df, palette='plasma')
plt.title('M√©dia de Do√ßura (Brix) por Nota de Qualidade')
plt.xlabel('Qualidade (1-5)')
plt.ylabel('M√©dia de Do√ßura (Brix)')
plt.tight_layout()
plt.savefig('barplot_brix_quality.png')

"""De acordo com o gr√°fico acima, observamos que h√° um tend√™ncia clara de aumento do Brix conforme a qualidade cresce, o que pode indicar que laranjas com alto brix, possuem uma  percep√ß√£o de qualidade maior, al√©m disso, a partir da nota 4.0 observa-se um aumento consider√°vel no brix.

Observa-se ainda que laranjas com qualidade 5.0 tem a m√©dia mais alta de brix, com erro pequeno, o que refor√ßa que as melhores laranjas s√£o as mais doces.
"""

#Correla√ß√£o de qualidade pelo peso
plt.figure(figsize=(12, 7))
sns.boxplot(x='Quality (1-5)', y='Weight (g)', data=df, palette='magma')
plt.title('Distribui√ß√£o do Peso (g) por Nota de Qualidade')
plt.xlabel('Qualidade (1-5)')
plt.ylabel('Peso (g)')
plt.tight_layout()
plt.savefig('boxplot_weight_quality.png')

"""De acordo com o gr√°fico acima, podemos observar que laranjas com notas de qualidade mais alta tendem a ser mais leves em compara√ß√£o com aquelas laranjas com qualidade inferior a 3.0 que apresenta mediana mais alta, al√©m disso frutas com qualidade >= 4.0 apresentam uma distribui√ß√£o de peso do tipo sim√©trica (normal),  com pesos medianos inferior a 225g, o que pode indicar que laranjas mais leve s√£o mais consistentes em qualidade.

Frutas com qualidade 1, 2, 2.5 e 3.5 apresentam maior variabilidade em sua distribui√ß√£o de peso, com assimetria a esquerda, indicando uma maior concentra√ß√£o de fruta com maior peso, por√©m menor qualidade.

"""

# #Correla√ß√£o de acidez com manchas
# plt.figure(figsize=(20, 6))
# sns.boxplot(x='Blemishes (Y/N)', y='pH (Acidity)', data=df, palette='crest')
# plt.title('Distribui√ß√£o da Acidez (pH) por Presen√ßa de Manchas')
# plt.xlabel('Presen√ßa de Manchas (Y/N)')
# plt.xticks(rotation=45, ha='right')
# plt.ylabel('pH (Acidez)')
# plt.tight_layout()
# plt.savefig('boxplot_ph_manchas.png')
# print("[OK] Gr√°fico 'boxplot_ph_manchas.png' foi salvo.")

"""Nota-se pelo gr√°fico acima que laranhas com manchas do tipo "Minor", "Sunburn", "Split Skin" e "Minor Insect Damage" possuem uma maior variablidade no pH, indicando que acidez dessa fruta √© menos previs√≠vel.

Laranjas com manchas classificadas como "Sunburn" possuem valores de pH mais concentrados ~4.1, o que pode indicar uma fruta com qualidade inferior (menos saborosa).

Nota-se ainda que laranjas classificadas como sem manchas "N" possuem uma acidez mais controlada e previs√≠vel variando seu pH entre 3.15 e 3.65, enquanto que laranjas com manchas, possuem uma maior variabilidade de pH, indicando assim que frutas sem manchas podem ser consideradas de melhor qualidade.



"""

#Correla√ß√£o da qualidade com manchas
df['Quality_Rounded'] = df['Quality (1-5)'].round().astype(int)
tabela_cruzada = pd.crosstab(df['Quality_Rounded'], df['Blemishes (Y/N)'])

print("\n--- Tabela Cruzada (Qualidade Arredondada vs. Manchas) ---")
print(tabela_cruzada)
print("----------------------------------------------------------")

# Visualizando a tabela cruzada com um mapa de calor
plt.figure(figsize=(10, 7))
sns.heatmap(tabela_cruzada, annot=True, cmap='YlGnBu', fmt='d')
plt.title('Mapa de Calor: Qualidade vs. Presen√ßa de Manchas')
plt.xlabel('Presen√ßa de Manchas (Y/N)')
plt.ylabel('Qualidade (Arredondada)')
plt.tight_layout()
plt.savefig('tabela_cruzada_heatmap_qualidade_manchas.png')
print("[OK] Gr√°fico 'tabela_cruzada_heatmap_qualidade_manchas.png' foi salvo.")

# df.head()

# Ajustar estilo
# sns.set(style="whitegrid", palette="muted", font_scale=1.1)

# # boxplot de Qualidade por presen√ßa de manchas
# plt.figure(figsize=(25,6))
# sns.boxplot(data=df, x="Blemishes (Y/N)", y="Quality (1-5)", palette="Set2")

# # Visualiza√ß√£o
# plt.title("Distribui√ß√£o da Qualidade por presen√ßa de mancha")
# plt.xlabel("presen√ßa de mancha")
# plt.ylabel("Nota de Qualidade (1-5)")
# plt.xticks(rotation=30)
# plt.show()

"""Nota-se pelo mapa de calor acima que a maior concentra√ß√£o de frutas (61%) est√° sem manchas (N), sendo que 78% das frutas sem manchas possuem qualidade >= 4.0, o que refor√ßa ainda mais a hip√≥tese de que frutas com maior percep√ß√£o de qualidade s√£o aquelas identificadas sem manchas (N).

Laranjas com presen√ßa de algum tipo de mancha tenden a se distribuir mais entre qualidades 2,3 e 4, raramente chegando a 5.

Frutas com manchas do tipo "Scars" e "Sunburn Patch" que foram as de maior ocorr√™ncia, apresentam qualidade entre 3 e 4, o que pode indicar uma qualidade intermedi√°ria.

Frutas com manchas por mofo (Mold Spot) e queimaduras de sol profundas (Sunburn) se mostraram com menores qualidades, enquanto que frutas com manchas por cicatrizes e outros danos ainda apresentam uma qualidade aceit√°vel, mas raramente de qualidade > 4.0.

#An√°lise Multivariada
"""

# @title Matriz de correla√ß√£o - Vari√°veis qualitativa ordinal e quantitativa cont√≠nua e discreta
corr = df.corr(numeric_only=True)
sns.heatmap(corr, annot=True, cmap="coolwarm")

df.describe()

#@title Gr√°fico de dispers√£o de duas vari√°veis com rela√ß√£o √† qualidade
sns.pairplot(df, hue='Quality (1-5)')
plt.suptitle("Gr√°fico de dispers√£o das vari√°veis", y=1.02)
plt.savefig('pair_plot.png')
plt.show()

# An√°lise de vari√°veis: Brix x pH x Qualidade
# sns.set(style="whitegrid")

# plt.figure(figsize=(10, 6))
# sns.scatterplot(
#     data=df,
#     x="Brix (Sweetness)",
#     y="pH (Acidity)",
#     size="Quality (1-5)",
#     hue="Quality (1-5)",
#     palette="viridis",
#     sizes=(20, 300),
#     alpha=0.9,
#     edgecolor="w"
# )

# plt.title("An√°lise Multivariada: Brix x pH x Quality")
# plt.show()

"""De acordo com o gr√°fico acima, temos:

*   **Tend√™ncia geral**: Existe uma tend√™ncia de alta qualidade associada a valores mais altos de brix, ou seja, quanto mais doce a fruta, maior a probabilidade de identificarmos uma percep√ß√£o de qualidade alta.

*   **Rela√ß√£o entre pH e qualidade**: As laranjas com qualidade mais alta aparecem em sua grande maioria com pH mais baixo (~2,8 - 3,4), o que pode indicar que uma acidez moderada-baixa combina melhor com uma fruta tida como de maior qualidade.

*  Interpreta√ß√£o pr√°tica: Para melhorar a qualidade da fruta √© prov√°vel que se deva buscar uma combina√ß√£o de maior brix e acidez moderada-baixa.
"""

# An√°lise de vari√°veis: Tamanho x Peso x Tempo de colheita
#sns.set(style="whitegrid")

#plt.figure(figsize=(10, 6))
#sns.scatterplot(
    #data=df,
    #x="Size (cm)",
    #y="Weight (g)",
    #size="HarvestTime (days)",
    #hue="HarvestTime (days)",
    #palette="viridis",
    #sizes=(20, 300),
    #alpha=0.9,
    #edgecolor="w"
#)

#plt.title("An√°lise Multivariada: Tamanho x Peso x Tempo de colheita")
#plt.show()

"""De acordo com o gr√°fico acima, temos:

*   **T√™ndencia geral**: Parece existir uma rela√ß√£o entre tempo de colheita e matura√ß√£o da fruta, de forma que, frutas colhidas mais tarde tendem a ser maiores e mais pesadas, o que sugere que o tempo de crescimento impacta diretamente a qualidade e massa da fruta.

*  Distribui√ß√£o do tempo de colheita: Frutas muito pequenas tendem a ter tempos de colheita menores, indicando que laranjas menores podem ter sido colhidas mais cedo, talvez por quest√µes de matura√ß√£o, manejo ou problemas fitossanit√°rios (Greening, Pinta Preta, Leprose entre outros).

"""

# An√°lise de vari√°veis: Brix x Tempo de Colheita x Qualidade
#sns.set(style="whitegrid")

#plt.figure(figsize=(10, 6))
#sns.scatterplot(
    #data=df,
    #x="HarvestTime (days)",
    #y="Brix (Sweetness)",

    #size="Quality (1-5)",
    #hue="Quality (1-5)",
    #palette="viridis",
    #sizes=(20, 300),
    #alpha=0.9,
    #edgecolor="w"
#)

#plt.title("An√°lise Multivariada: Brix x Tempo de colheita x Qualidade")
#plt.show()

"""Observa-se que pontos maiores e mais claros e portanto com maior qualidade aparecem mais em tempos de colheita entre 10 - 18 dias, com brix variando entre 10 - 16. Isso pode indicar que esta janela temporal pode gerar frutos de melhor qualidade.

Colher entre 10 - 18 dias provavelmente maximiza a qualidade e do√ßura da fruta. Colheitas muito precoces ou muito tardias tendem a gerar frutas com qualidade inferior.

"""

# An√°lise de vari√°veis: Softness x pH x Qualidade
#sns.set(style="whitegrid")

#plt.figure(figsize=(10, 6))
#sns.scatterplot(
    #data=df,
    #x="pH (Acidity)",
    #y="Softness (1-5)",

    #size="Quality (1-5)",
    #hue="Quality (1-5)",
    #palette="viridis",
    #sizes=(20, 300),
    #alpha=0.9,
    #edgecolor="w"
#)

"""Observa-se pelos 2 √∫ltimos gr√°ficos acima que pontos com maior qualidade parecem estar mais concentrados em pH at√© 3.6 e maciez at√© 3.0, isso sugere que frutas com pH moderado e boa maciez apresentam em m√©dia maior qualidade.

H√° pontos com alta maciez (>4.0) mas qualidade baixa, indicando que pH tambem √© um determinante cr√≠tico da qualidade da fruta e portanto a vari√°vel maciez por si s√≥ n√£o √© um bom preditor de qualidade.

# üìä An√°lise de Correla√ß√£o da Qualidade da Laranja

---

## üçä Principais Insights sobre Qualidade

O fator que mais influencia a **Qualidade (1-5)** √© o **Brix**. O **tempo de colheita** tamb√©m √© relevante, mas tende a reduzir a qualidade.

### 1. Brix √© o Fator Mais Forte  
- **Brix (do√ßura)** tem a correla√ß√£o positiva mais alta com a Qualidade ($0,63$). Isso indica que o n√≠vel de do√ßura √© o atributo mais importante.

### 2. Tempo de Colheita Impacta Negativamente  
- **HarvestTime (dias)** tem a segunda correla√ß√£o mais forte, mas negativa ($-0,47$).  
- Isso indica que colher mais tarde est√° ligado a uma queda na qualidade.
- Existe um per√≠odo ideial para o colheita, aproximadamente 10 a 18 dias.

### 3. Frutas Menores/Leves Tendem a Ter Qualidade Maior  
- **Size (cm)** e **Weight (g)** t√™m correla√ß√£o negativa fraca com Qualidade ($-0,24$).  
- Pequenas diferen√ßas sugerem que frutas ligeiramente menores ou mais leves podem ser percebidas como de qualidade melhor.

### 4. Equil√≠brio √© Importante
- Al√©m da do√ßura, √© essencial ter um equil√≠brio entre **Acidez(pH)** e **textura(maciez)**.
- Laranjas de alta qualidade n√£o s√£o excessivas em ambas categorias.

---

## üß™ Hip√≥teses para Explorar

**Hip√≥tese 1:** Tempo de colheita afeta qualidade via Brix.  
- *HarvestTime* tem correla√ß√£o negativa com Qualidade ($-0,47$) e com Brix ($-0,33$).  
- Ap√≥s certo ponto, esperar mais tempo n√£o aumenta o Brix e pode degradar compostos importantes para a qualidade. H√° uma janela ideal de colheita.

**Hip√≥tese 2:** Acidez e textura afetam qualidade.  
- *pH (Acidity)* ($-0,32$) e *Softness (1-5)* ($-0,30$) t√™m correla√ß√£o negativa moderada com Qualidade.  
- Consumidores tendem a preferir laranjas menos √°cidas e mais firmes. Frutas muito macias podem indicar matura√ß√£o excessiva ou danos.

---

## ‚úÖ Recomenda√ß√µes

Para melhorar a qualidade da laranja:  
1. Priorizar o aumento do **Brix (do√ßura)**.  
2. Definir o ponto ideal de colheita para evitar perda de qualidade.

**Objetivo:**
- Colher a laranja quando ela atinge o pico de **Do√ßura(Brix)**, antes que a laranja degrade e afete o seu sabor.

> Priorizar apenas tamanho ou atrasar a colheita pode reduzir a qualidade final.

---
üìä ENTREGA 02
---
"""

# 1.1 - Entendimento inicial da base
#df.info()
#df.describe()
#df.head()

# resultado : N√£o foram identificados valores ausentes, portanto n√£o foi necess√°rio aplicar t√©cnicas de imputa√ß√£o.

# 1.2 Codifica√ß√£o de vari√°veis qualitativas

#print("Colunas Antes:", df.shape) # Verificando quantas colunas tinhamos antes da codifica√ß√£o (Aplicado somente a coluna categ√≥ricas)
#df_encoded = pd.get_dummies(df, columns=["Color", "Variety", "Blemishes (Y/N)"], drop_first=True) # Identifica√ß√£o de colunas categ√≥ricas e codifica√ß√£o para TRUE/FALSE
#print("Colunas Depois:", df_encoded.shape) # Verificando quantas colunas temos ap√≥s codifica√ß√£o (O n√∫mero de linhas (241) deve se manter)
#df_encoded = df_encoded.astype(int) # Convertendo TRUE/FALSE para 0/1 que √© o ideal para modelos de Machine Learning
#df_encoded.head() # Visualiza√ß√£o das primeiras 5 linhas do novo dataframe gerado (j√° codificado)

# Verifica√ß√£o se ainda existe alguma outra coluna categ√≥rica.
#df_encoded.select_dtypes(include='object').columns

# Resultado -> N√£o existe e a base esta pronta para normaliza√ß√£o

# 1.3 Normaliza√ß√£o de vari√°veis quantitativas (Colocando as vari√°veis na mesma escala para evitar eventuais distor√ß√£o nos modelos de ML)

#from sklearn.preprocessing import StandardScaler

# Selecionando somente colunas num√©ricas do novo dataframe (j√° codificado)
#numeric_cols = df_encoded.select_dtypes(include=['int64', 'float64']).columns


# Removendo a vari√°vel alvo (target) da normaliza√ß√£o
#targets = ['Quality (1-5)', 'Quality_Rounded'] # se formos usar modelo de classifica√ß√£o, ent√£o considero que melhor usarmos como target a coluna "Quality_Rounded", caso modelo de regress√£o ent√£o podemos usar "Quality (1-5)"

#numeric_cols = [col for col in numeric_cols if col not in targets]


# Criando o scaler (padronizando as  vari√°veis)
#scaler = StandardScaler()

# Aplicando normaliza√ß√£o -> fit_transform ajusta o scaler aos dados e transforma as colunas
#df_encoded[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])

#df_encoded.head() # Visualizado o data frame j√° pronto para ser consumido em modelo de ML

# 1.4 Tratando outliers (valores discrepantes)

## visualizando eventuais outliers
#import matplotlib.pyplot as plt
#import seaborn as sns

# Selecionando colunas num√©ricas cont√≠nuas para vizualiza√ß√£o
#plt.figure(figsize=(15,8))
#sns.boxplot(data=df_encoded[numeric_cols].melt(), x='variable', y='value')
#plt.xticks(rotation=90)
#plt.show()

#print(df_encoded.to_string()) # Visualizando todo o data frame

# Fazendo a remo√ß√£o dos outliers
#from scipy import stats
#df_encoded = df_encoded[(np.abs(stats.zscore(df_encoded[numeric_cols])) < 3).all(axis=1)]

# Visualizando o dataframe ap√≥s identifica√ß√£o e remo√ß√£o dos outliers
#plt.figure(figsize=(15,8))
#sns.boxplot(data=df_encoded[numeric_cols].melt(), x='variable', y='value')
#plt.xticks(rotation=90)
#plt.show()

# @title Importando bibliotecas do Scikit-learn

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# Pr√©-processamento
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import (
    train_test_split, cross_validate,
    RandomizedSearchCV, ShuffleSplit
)
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Modelos
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# Utilit√°rios para suprimir avisos
import warnings
from sklearn.exceptions import ConvergenceWarning

df = pd.read_csv('https://raw.githubusercontent.com/atlantico-academy/datasets/refs/heads/main/orange_quality.csv')
df

# @title Processando 'Blemishes (Y/N)'
print("Valores √∫nicos antes da transforma√ß√£o:")
print(df['Blemishes (Y/N)'].value_counts().head())

# Criar a nova coluna bin√°ria 'Blemishes'
df['Blemishes'] = df['Blemishes (Y/N)'].apply(lambda x: 0 if 'N' in x else 1)

print("\nValores √∫nicos depois da transforma√ß√£o:")
print(df['Blemishes'].value_counts())

# @title Definindo X, y e separando Treino/Teste

# Convertendo a coluna alvo para inteiro
df['Quality (1-5)'] = df['Quality (1-5)'].astype(int)

# Definindo X (features) e y (alvo)
X = df.drop(['Quality (1-5)', 'Blemishes (Y/N)'], axis=1)
y = df['Quality (1-5)']

# Separar em treino e teste (estratificado pela vari√°vel alvo 'y')
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print(f"Tamanho de X_train: {X_train.shape}")
print(f"Tamanho de X_test: {X_test.shape}")

# @title Definindo o ColumnTransformer

# 1. Definir colunas num√©ricas
numeric_features = [
    'Size (cm)', 'Weight (g)', 'Brix (Sweetness)', 'pH (Acidity)',
    'Softness (1-5)', 'HarvestTime (days)', 'Ripeness (1-5)', 'Blemishes'
]

# 2. Definir colunas categ√≥ricas
categorical_features = ['Color', 'Variety']

# 3. Criar o pr√©-processador (ColumnTransformer)
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
    ],
    remainder='passthrough'
)

"""### Usamos o Standardascaler e OneHotEncoder, um para os dados num√©ricos e outro para os dados categ√≥ricos, respectivamente. Devido √†s caracter√≠sticas dos dados, pois √© mais simples e eficiente apenas dividir os dados em duas categorias, onde os num√©ricos tem um objetivo em comum que √© o escalonamento. Enquanto os dados categ√≥ricos, apenas os tranformamos em n√∫meros."""

# @title Definindo Modelos e Grades de Par√¢metros

# 1. Definindo os modelos
models = {
    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),
    'DecisionTree': DecisionTreeClassifier(random_state=42),
    'RandomForest': RandomForestClassifier(random_state=42),
    'SVC': SVC(probability=True, random_state=42),
    'KNN': KNeighborsClassifier(),
    'GradientBoosting': GradientBoostingClassifier(random_state=42)
}

# 2. Definindo as grades de par√¢metros para otimiza√ß√£o
param_grids = {
    'LogisticRegression': {
        'classifier__C': [0.1, 1.0, 10, 100],
        'classifier__solver': ['liblinear', 'lbfgs']
    },
    'DecisionTree': {
        'classifier__max_depth': [None, 10, 20, 30],
        'classifier__min_samples_leaf': [1, 2, 4],
        'classifier__min_samples_split': [2, 5, 10]
    },
    'RandomForest': {
        'classifier__n_estimators': [100, 200, 300],
        'classifier__max_depth': [None, 10, 20],
        'classifier__min_samples_leaf': [1, 2, 4]
    },
    'SVC': {
        'classifier__C': [0.1, 1, 10],
        'classifier__gamma': ['scale', 'auto'],
        'classifier__kernel': ['rbf', 'linear']
    },
    'KNN': {
        'classifier__n_neighbors': [3, 5, 7, 9, 11]
    },
    'GradientBoosting': {
        'classifier__n_estimators': [100, 200, 300],
        'classifier__learning_rate': [0.01, 0.1, 0.2],
        'classifier__max_depth': [3, 5, 7]
    }
}

"""**Regress√£o Log√≠stica:** Modelo base, se os modelos complexos n√£o forem melhor que ele, ent√£o a rela√ß√£o entre as features √© simples e linear, assim como o modelo.

**KNN:** Modelo baseado em inst√¢ncias, ideal para detectar rel√ß√µes complexas que modelos lineares n√£o enxergariam.

**√Årvore de Decis√£o:** √â f√°cil de interpretar e entender como funciona as decis√µes do modelo, al√©m de ser a base dos modelos ensemble.

**Floresta Aleat√≥ria:** √â um modelo robusto que costuma ter bons desempenhos, onde ele constroi v√°rias √°rvores, com amostras aleat√≥rias, dos dados e das features, no final √© decidido qual a melhor √°rvore.

**GBM:** √â um modelo de muito desempenho em dados tabulares, que se diferencia da floresta aleat√≥ria pelo fato de construir √°rvores para corrigir problemas da anterior, ou seja, teoricamente a cada √°rvore o modelo melhora.

**SVC:** √â um modelo diferente que usa uma abordagem geom√©trica baseada em kernels, tentando encontrar o "hiperplano" que separa as classes com maior dist√¢ncia poss√≠vel.
"""

# @title Executando a Otimiza√ß√£o (RandomizedSearchCV)

best_models = {}

# Suprimir avisos de converg√™ncia durante a otimiza√ß√£o
with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=ConvergenceWarning)

    for model_name in models.keys():
        print(f"Otimizando {model_name}...")

        # Criar o pipeline completo
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', models[model_name])
        ])

        # Obter a grade de par√¢metros
        param_dist = param_grids[model_name]

        if not param_dist:
            best_models[model_name] = pipeline
            print(f"{model_name} n√£o possui hiperpar√¢metros para otimizar.")
            continue

        search = RandomizedSearchCV(
            pipeline,
            param_dist,
            n_iter=10,
            cv=5,
            scoring='accuracy',
            random_state=42,
            n_jobs=-1,
            error_score='raise'
        )

        # Executar a busca nos dados de treino
        search.fit(X_train, y_train)

        # Salvar o melhor pipeline encontrado
        best_models[model_name] = search.best_estimator_
        print(f"Melhor acur√°cia (CV interna) para {model_name}: {search.best_score_:.4f}")

print("\n--- Otimiza√ß√£o conclu√≠da ---")
print(f"Modelos otimizados armazenados: {list(best_models.keys())}")

# @title Executando a Valida√ß√£o Monte Carlo

# 1. Definir a estrat√©gia de Valida√ß√£o Cruzada Monte Carlo
cv_strategy = ShuffleSplit(n_splits=30, test_size=0.2, random_state=42)

# 2. Definir as m√©tricas
scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc_ovr']

# 3. Dicion√°rio para armazenar resultados
model_results = {}

# 4. Loop de avalia√ß√£o
print("Executando Valida√ß√£o Monte Carlo (ShuffleSplit)...")
for model_name, optimized_pipeline in best_models.items():
    print(f"Avaliando {model_name} (otimizado)...")

    # Executar o cross-validate usando o pipeline otimizado e a estrat√©gia ShuffleSplit
    scores = cross_validate(
        optimized_pipeline,
        X_train,
        y_train,
        cv=cv_strategy,
        scoring=scoring_metrics,
        n_jobs=-1
    )
    model_results[model_name] = scores

print("\n--- Valida√ß√£o Monte Carlo conclu√≠da ---")

# @title Convertendo resultados para DataFrame

results_list = []
for model_name, scores in model_results.items():
    for metric in scoring_metrics:
        score_key = f'test_{metric}'
        if score_key in scores:
            for score_value in scores[score_key]:
                results_list.append({
                    'modelo': model_name,
                    'M√©trica': metric,
                    'Score': score_value
                })

results_df = pd.DataFrame(results_list)

print("Resultados da Valida√ß√£o Monte Carlo (primeiras linhas):")
display(results_df)

metrics_to_plot = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']
plot_data_filtered = results_df[results_df['M√©trica'].isin(metrics_to_plot)]

pivot_table = pd.pivot_table(
    plot_data_filtered,
    values='Score',
    index='M√©trica',
    columns='modelo',
    aggfunc=['mean', 'std']
)

# Reordenar as linhas (m√©tricas) para ficarem na ordem desejada
pivot_table = pivot_table.reindex(metrics_to_plot)

pd.options.display.float_format = '{:.4f}'.format

print("\nTabela Piv√¥ (M√©dia e Desvio Padr√£o):")
print(pivot_table)

# @title Visualiza√ß√£o dos Resultados (Gr√°fico de Barras)

# Criar o gr√°fico (Catplot com kind='bar')
g = sns.catplot(
    data=plot_data_filtered,
    x='modelo',
    y='Score',
    col='M√©trica',
    kind='bar',
    height=6,
    aspect=1.2,
    palette='viridis',
    order=sorted(plot_data_filtered['modelo'].unique())
)

# Ajustes de t√≠tulo e r√≥tulos
g.fig.suptitle("Compara√ß√£o de Desempenho (Valida√ß√£o Monte Carlo, 30 itera√ß√µes)", y=1.03, fontsize=16)
g.set_titles("{col_name}", size=14)
g.set_axis_labels("Modelo (Otimizado)", "Pontua√ß√£o M√©dia (Score)", size=12)
g.set_xticklabels(rotation=30, ha='right')

# Ajustar o layout
plt.tight_layout()

#Salvar a imagem
image_filename = "model_comparison_monte_carlo_bars.png"
plt.savefig(image_filename, bbox_inches='tight', dpi=150)

print(f"Gr√°fico de compara√ß√£o (barras) salvo em '{image_filename}'")
plt.show()

# @title Visualiza√ß√£o dos Resultados (Boxplot)

# Criar o gr√°fico (Catplot com kind='box')
g = sns.catplot(
    data=plot_data_filtered,
    x='modelo',
    y='Score',
    col='M√©trica',
    kind='box',
    height=6,
    aspect=1.2,
    palette='viridis',
    order=sorted(plot_data_filtered['modelo'].unique())
)

# Ajustes de t√≠tulo e r√≥tulos
g.fig.suptitle("Compara√ß√£o de Desempenho (Valida√ß√£o Monte Carlo, 30 itera√ß√µes)", y=1.03, fontsize=16)
g.set_titles("{col_name}", size=14)
g.set_axis_labels("Modelo (Otimizado)", "Pontua√ß√£o (Score)", size=12)
g.set_xticklabels(rotation=30, ha='right')

# Ajustar o layout
plt.tight_layout()

# Salvar a imagem
image_filename = "model_comparison_monte_carlo.png"
plt.savefig(image_filename, bbox_inches='tight', dpi=150)

print(f"Gr√°fico de compara√ß√£o salvo em '{image_filename}'")
plt.show()

# @title Compara√ß√£o de Modelos como as melhores resultados
results_list = []
for model_name, scores in model_results.items():
    for metric in scoring_metrics:
        score_key = f'test_{metric}'
        if score_key in scores:
            for score_value in scores[score_key]:
                results_list.append({
                    'modelo': model_name,
                    'M√©trica': metric,
                    'Score': score_value
                })
results_df = pd.DataFrame(results_list)

max_scores = results_df.groupby(['modelo', 'M√©trica'])['Score'].max().unstack()
max_scores = max_scores[scoring_metrics]

print("\n--- Maiores Scores (Valida√ß√£o Monte Carlo) por Modelo Otimizado ---")
print(max_scores)

# 1. Identificar os 3 melhores modelos com base no f1_macro M√ÅXIMO
best_model_names_max = max_scores.sort_values(by='f1_macro', ascending=False).index[:3].tolist()

print("\n--- An√°lise do Top 3 (Baseado no Score M√°ximo) ---")
print(f"Os 3 melhores modelos (baseado no f1_macro m√°ximo) s√£o: {', '.join(best_model_names_max)}")

# 2. Filtrar a tabela de m√©dias e o DataFrame completo de resultados
top_max_scores = max_scores.loc[best_model_names_max]
# Usamos o 'results_df' original para os boxplots
top_results_df = results_df[results_df['modelo'].isin(best_model_names_max)]

print("\n--- Maiores Scores (Top 3 Modelos) ---")
print(top_max_scores)

# 3. Gerar novo gr√°fico de boxplot focado nos 3 melhores
# O boxplot ainda mostra a distribui√ß√£o completa (as 30 itera√ß√µes),
# o que √© bom para vermos a variabilidade.
metrics_to_plot = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']
plot_data_filtered = top_results_df[top_results_df['M√©trica'].isin(metrics_to_plot)]

g = sns.catplot(
    data=plot_data_filtered,
    x='modelo',
    y='Score',
    col='M√©trica',
    kind='box',
    height=6,
    aspect=1.0,
    palette='viridis',
    order=best_model_names_max
)

# T√≠tulo e r√≥tulos
g.fig.suptitle("Compara√ß√£o de Desempenho (Top 3 Modelos - Scores M√°ximos)", y=1.03, fontsize=16)
g.set_titles("{col_name}", size=14)
g.set_axis_labels("Modelo (Otimizado)", "Pontua√ß√£o (Score)", size=12)
g.set_xticklabels(rotation=0)

plt.tight_layout()

# Salvar a imagem final
image_filename = "top_3_model_max_score_comparison.png"
plt.savefig(image_filename, bbox_inches='tight', dpi=150)

print(f"\nGr√°fico de compara√ß√£o do Top 3 (baseado em max score) salvo em '{image_filename}'")

"""**Acur√°cia:** √â a m√©trica mais intuitiva, responde simplesmente qual a porcentagem de laranjas que o modelo acertou a qualidade.

**Precis√£o Macro:** √â importante saber o quanto o modelo previu de falsos positivos, nesse caso utilizamos o macro para saber a precis√£o de cada classe e fazer uma m√©dia simples, dessa maneira se o modelo for muito bom em prever nota 5 que √© mais comum, mas muito ruim em prever nota 1 que √© mais incomum, ent√£o a m√©dia ser√° baixa, ou seja, penalizando por ignorar a classe rara.

**Recall Macro:** Assim como a precis√£o, mas agora para os falsos negativos, ou seja, de todas as laranjas que eram nota 1, de quantas conseguiu identificar corretamente? Ele responde se o modelo tem dificuldade em encontrar classes menos frequ√™ntes.

**F1-Score Macro:** √â uma m√©dia entre os dois casos anteriores, ou seja, se est√° m√©trica estiver alta, fala que o modelo √© bom em identificar todas as classes n√£o apenas as mais comuns.

**ROC AUC One-vs-Rest:** Ela obsera a capacidade da separa√ß√£o do modelo. Medindo a habilidade do modelo de dar um pontua√ß√£o de probabiliade mais alta para a classe correta do que para as demais, como ROC AUC √© bin√°rio o One-vs-Rest adapta essa m√©trica para um caso de multi-classe, dessa maneira ela testa cada classe em compara√ß√£o ao resto e faz uma m√©dia.

---
An√°lise dos resultado e Conclus√µes
---
"""

import matplotlib.image as mpimg
img1 = mpimg.imread('model_comparison_monte_carlo.png')
img2 = mpimg.imread('top_3_model_max_score_comparison.png')
plt.figure(figsize=(17, 12))
plt.imshow(img1)

plt.figure(figsize=(15, 10))
plt.imshow(img2)

"""1¬∫ O melhor modelo √© o SVC: Se fosse para escolher um modelo para colocar em produ√ß√£o com este dataset, seria o SVC. Ele provou ser o mais equilibrado, com o melhor f1_macro, sendo superior tanto em precis√£o quanto em capacidade de encontrar classes raras.

2¬∫ Por que a Regress√£o Log√≠stica teve uma acur√°cia t√£o alta: O desempenho surpreendentemente forte de um modelo linear (LogisticRegression) e o desempenho decepcionante de um modelo complexo (GradientBoosting) s√£o sintomas cl√°ssicos de um conjunto de dados pequeno. Os modelos complexos n√£o t√™m dados suficientes para melhorar o seu desempenho.

3¬∫ Podemos inferir que se tivessemos dados mais robustos, uma quantidade mais alta, provavelente modelos como o floresta aleat√≥ria e o Gradient Boosting produzissem resultados melhores, por√©m com os dados que temos o mais equilibrado mesmo √© o SVC.

4¬∫ Quando olhamos para os valores m√°ximos, vemos que a regrass√£o log√≠stica obteve a maior acur√°cia, isso mostrar que em alguma combina√ß√£o de hiperpar√¢metros otimiza seu desempenho, por√©m ainda n√£o obteve outras m√©tricas melhores que o SVC.

5¬∫ Por que mesmo o SVC estando atr√°s da Regrass√£o Log√≠stica e do KNN, na m√©trica ROC AUC, ele continua sendo o melhor? Porque mesmo que KNN e Regress√£o Log√≠stica ainda t√™m precis√£o e recall menores que o SVC, quando analisamos os m√°ximos, o que deixa a entender que esses dois modelos ficaram bons em diferenciar as categorias mais comuns, por√©m n√£o s√£o t√£o bons com as mais raras, enquanto o SVC tem um equil√≠brio muito melhor. Dessa forma, se a amostra tivesse uma variabilidade maior de dados, talvez esses modelos n√£o teriam tais n√∫meros.
"""